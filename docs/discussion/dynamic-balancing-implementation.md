# Defense Allies ë™ì  ë°¸ëŸ°ì‹± ì‹œìŠ¤í…œ êµ¬í˜„

## ğŸ“‹ ë¬¸ì„œ ì •ë³´
- **ì‘ì„±ì¼**: 2024ë…„
- **ë²„ì „**: v1.0
- **ëª©ì **: ì‹¤ì‹œê°„ ê²Œì„ ë°¸ëŸ°ìŠ¤ ëª¨ë‹ˆí„°ë§ ë° ìë™ ì¡°ì • ì‹œìŠ¤í…œ êµ¬í˜„
- **ê¸°ë°˜**: [18ì¢…ì¡± ë§¤íŠ¸ë¦­ìŠ¤ ìµœì í™”](18-race-matrix-optimization.md)

## ğŸ¯ ë™ì  ë°¸ëŸ°ì‹± ëª©í‘œ

### í•µì‹¬ ì›ì¹™
1. **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: ê²Œì„ ì¤‘ ì§€ì†ì ì¸ ë°¸ëŸ°ìŠ¤ ìƒíƒœ ì¶”ì 
2. **ìë™ ì¡°ì •**: ë¶ˆê· í˜• ê°ì§€ ì‹œ ì¦‰ì‹œ í™˜ê²½ ë³€ìˆ˜ë¡œ ë³´ì •
3. **í”Œë ˆì´ì–´ ê²½í—˜ ë³´ì¡´**: ë°¸ëŸ°ì‹±ì´ ê²Œì„ ì¬ë¯¸ë¥¼ í•´ì¹˜ì§€ ì•Šë„ë¡
4. **ì˜ˆì¸¡ì  ì¡°ì •**: ë¯¸ë˜ ë¶ˆê· í˜• ìƒí™© ì˜ˆì¸¡ ë° ì‚¬ì „ ëŒ€ì‘

## ğŸ” ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

### ë°¸ëŸ°ìŠ¤ ë©”íŠ¸ë¦­ ì •ì˜
```python
import numpy as np
from dataclasses import dataclass
from typing import Dict, List, Tuple
import time

@dataclass
class BalanceMetrics:
    """ê²Œì„ ë°¸ëŸ°ìŠ¤ ì¸¡ì • ì§€í‘œ"""
    frobenius_variance: float      # íŒ€ ê°„ íŒŒì›Œ ë¶„ì‚°
    win_rate_deviation: float      # ìŠ¹ë¥  í¸ì°¨
    resource_efficiency: float     # ìì› íš¨ìœ¨ì„± ì°¨ì´
    cooperation_index: float       # í˜‘ë ¥ í™œìš©ë„
    adaptation_speed: float        # í™˜ê²½ ì ì‘ ì†ë„
    
    def overall_balance_score(self) -> float:
        """ì¢…í•© ë°¸ëŸ°ìŠ¤ ì ìˆ˜ (0~1, 1ì´ ì™„ë²½í•œ ê· í˜•)"""
        weights = [0.3, 0.25, 0.2, 0.15, 0.1]
        metrics = [
            1.0 / (1.0 + self.frobenius_variance),
            1.0 / (1.0 + self.win_rate_deviation),
            1.0 / (1.0 + abs(self.resource_efficiency - 1.0)),
            self.cooperation_index,
            self.adaptation_speed
        ]
        return sum(w * m for w, m in zip(weights, metrics))

class GameStateMonitor:
    """ê²Œì„ ìƒíƒœ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§"""
    
    def __init__(self, update_interval: float = 30.0):
        self.update_interval = update_interval
        self.balance_history: List[BalanceMetrics] = []
        self.player_matrices: Dict[str, np.ndarray] = {}
        self.environment_state = {
            'time': 'day',
            'weather': 'clear', 
            'terrain': 'plain'
        }
        
    def update_player_state(self, player_id: str, race: str, 
                           towers: List[Dict], resources: Dict):
        """í”Œë ˆì´ì–´ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        # í˜„ì¬ í”Œë ˆì´ì–´ì˜ íš¨ê³¼ì ì¸ íŒŒì›Œ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
        base_matrix = self.get_race_matrix(race)
        tower_bonus = self.calculate_tower_bonus(towers)
        env_modifier = self.get_environment_modifier(race)
        
        effective_matrix = base_matrix * tower_bonus * env_modifier
        self.player_matrices[player_id] = effective_matrix
        
    def calculate_current_balance(self) -> BalanceMetrics:
        """í˜„ì¬ ë°¸ëŸ°ìŠ¤ ìƒíƒœ ê³„ì‚°"""
        if len(self.player_matrices) < 2:
            return BalanceMetrics(0, 0, 1, 1, 1)
            
        matrices = list(self.player_matrices.values())
        
        # 1. í”„ë¡œë² ë‹ˆìš°ìŠ¤ ë…¸ë¦„ ë¶„ì‚°
        norms = [np.linalg.norm(matrix, 'fro') for matrix in matrices]
        frobenius_var = np.var(norms)
        
        # 2. ìŠ¹ë¥  í¸ì°¨ (ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜)
        win_rates = self.simulate_win_rates(matrices)
        win_rate_dev = np.std(win_rates)
        
        # 3. ìì› íš¨ìœ¨ì„±
        resource_eff = self.calculate_resource_efficiency()
        
        # 4. í˜‘ë ¥ ì§€ìˆ˜
        coop_index = self.calculate_cooperation_index()
        
        # 5. ì ì‘ ì†ë„
        adapt_speed = self.calculate_adaptation_speed()
        
        return BalanceMetrics(
            frobenius_variance=frobenius_var,
            win_rate_deviation=win_rate_dev,
            resource_efficiency=resource_eff,
            cooperation_index=coop_index,
            adaptation_speed=adapt_speed
        )
    
    def simulate_win_rates(self, matrices: List[np.ndarray]) -> List[float]:
        """ë§¤íŠ¸ë¦­ìŠ¤ ê¸°ë°˜ ìŠ¹ë¥  ì‹œë®¬ë ˆì´ì…˜"""
        win_rates = []
        
        for i, matrix_i in enumerate(matrices):
            wins = 0
            total_matches = 0
            
            for j, matrix_j in enumerate(matrices):
                if i != j:
                    # ë§¤íŠ¸ë¦­ìŠ¤ ëŒ€ê²° ì‹œë®¬ë ˆì´ì…˜
                    power_i = np.linalg.norm(matrix_i, 'fro')
                    power_j = np.linalg.norm(matrix_j, 'fro')
                    
                    # ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ë¡œ ìŠ¹ë¥  ê³„ì‚°
                    win_prob = 1 / (1 + np.exp(-(power_i - power_j)))
                    wins += win_prob
                    total_matches += 1
            
            win_rates.append(wins / total_matches if total_matches > 0 else 0.5)
        
        return win_rates

class AdaptiveEnvironmentGenerator:
    """ì ì‘í˜• í™˜ê²½ ìƒì„±ê¸°"""
    
    def __init__(self):
        self.environment_effects = self.load_environment_matrices()
        self.balance_threshold = 0.7  # ë°¸ëŸ°ìŠ¤ ì ìˆ˜ ì„ê³„ê°’
        
    def generate_balancing_environment(self, 
                                     current_matrices: Dict[str, np.ndarray],
                                     target_balance: float = 0.85) -> Dict[str, str]:
        """ë°¸ëŸ°ì‹±ì„ ìœ„í•œ ìµœì  í™˜ê²½ ìƒì„±"""
        
        best_env = None
        best_score = 0
        
        # ëª¨ë“  í™˜ê²½ ì¡°í•© í…ŒìŠ¤íŠ¸
        for time in ['dawn', 'day', 'dusk', 'night']:
            for weather in ['clear', 'rain', 'storm', 'snow', 'fog']:
                for terrain in ['plain', 'forest', 'mountain', 'desert', 'swamp', 'urban']:
                    
                    # ì´ í™˜ê²½ì—ì„œì˜ ë°¸ëŸ°ìŠ¤ ì ìˆ˜ ê³„ì‚°
                    env_score = self.evaluate_environment_balance(
                        current_matrices, time, weather, terrain
                    )
                    
                    if env_score > best_score:
                        best_score = env_score
                        best_env = {
                            'time': time,
                            'weather': weather, 
                            'terrain': terrain
                        }
        
        return best_env
    
    def evaluate_environment_balance(self, 
                                   matrices: Dict[str, np.ndarray],
                                   time: str, weather: str, terrain: str) -> float:
        """íŠ¹ì • í™˜ê²½ì—ì„œì˜ ë°¸ëŸ°ìŠ¤ ì ìˆ˜ í‰ê°€"""
        
        # í™˜ê²½ íš¨ê³¼ ì ìš©
        modified_matrices = {}
        for player_id, matrix in matrices.items():
            race = self.get_player_race(player_id)
            env_modifier = self.get_environment_modifier(race, time, weather, terrain)
            modified_matrices[player_id] = matrix * env_modifier
        
        # ìˆ˜ì •ëœ ë§¤íŠ¸ë¦­ìŠ¤ë“¤ì˜ ë°¸ëŸ°ìŠ¤ ì ìˆ˜ ê³„ì‚°
        norms = [np.linalg.norm(matrix, 'fro') for matrix in modified_matrices.values()]
        variance = np.var(norms)
        
        # ë¶„ì‚°ì´ ë‚®ì„ìˆ˜ë¡ ì¢‹ì€ ì ìˆ˜
        return 1.0 / (1.0 + variance)

class DynamicBalancer:
    """ë™ì  ë°¸ëŸ°ì‹± ë©”ì¸ ì—”ì§„"""
    
    def __init__(self):
        self.monitor = GameStateMonitor()
        self.env_generator = AdaptiveEnvironmentGenerator()
        self.balance_history: List[Tuple[float, BalanceMetrics]] = []
        self.intervention_cooldown = 120.0  # 2ë¶„ ì¿¨ë‹¤ìš´
        self.last_intervention = 0
        
    def run_balancing_cycle(self):
        """ë°¸ëŸ°ì‹± ì‚¬ì´í´ ì‹¤í–‰"""
        current_time = time.time()
        
        # í˜„ì¬ ë°¸ëŸ°ìŠ¤ ìƒíƒœ ì¸¡ì •
        current_balance = self.monitor.calculate_current_balance()
        balance_score = current_balance.overall_balance_score()
        
        # ê¸°ë¡ ì €ì¥
        self.balance_history.append((current_time, current_balance))
        
        # ë°¸ëŸ°ìŠ¤ ì ìˆ˜ê°€ ì„ê³„ê°’ ì´í•˜ì´ê³  ì¿¨ë‹¤ìš´ì´ ëë‚¬ë‹¤ë©´
        if (balance_score < 0.7 and 
            current_time - self.last_intervention > self.intervention_cooldown):
            
            self.trigger_balancing_intervention(current_balance)
            self.last_intervention = current_time
    
    def trigger_balancing_intervention(self, current_balance: BalanceMetrics):
        """ë°¸ëŸ°ì‹± ê°œì… ì‹¤í–‰"""
        
        # 1. í™˜ê²½ ë³€ê²½ì„ í†µí•œ ë°¸ëŸ°ì‹±
        if current_balance.frobenius_variance > 0.5:
            new_env = self.env_generator.generate_balancing_environment(
                self.monitor.player_matrices
            )
            self.apply_environment_change(new_env)
        
        # 2. ì„ì‹œ ë²„í”„/ë””ë²„í”„ ì ìš©
        if current_balance.win_rate_deviation > 0.3:
            self.apply_temporary_adjustments()
        
        # 3. íŠ¹ìˆ˜ ì´ë²¤íŠ¸ ë°œìƒ
        if current_balance.cooperation_index < 0.4:
            self.trigger_cooperation_event()
    
    def apply_environment_change(self, new_environment: Dict[str, str]):
        """í™˜ê²½ ë³€ê²½ ì ìš©"""
        print(f"ğŸŒ í™˜ê²½ ë³€ê²½: {new_environment}")
        
        # ê²Œì„ ì„œë²„ì— í™˜ê²½ ë³€ê²½ ëª…ë ¹ ì „ì†¡
        self.send_environment_update(new_environment)
        
        # í”Œë ˆì´ì–´ë“¤ì—ê²Œ ì•Œë¦¼
        self.notify_players_environment_change(new_environment)
    
    def apply_temporary_adjustments(self):
        """ì„ì‹œ ì¡°ì • ì ìš©"""
        
        # ê°€ì¥ ì•½í•œ íŒ€ì—ê²Œ ì„ì‹œ ë²„í”„
        weakest_players = self.identify_weakest_players()
        
        for player_id in weakest_players:
            buff_matrix = np.array([[1.1, 1.05], [1.05, 1.1]])
            self.apply_temporary_buff(player_id, buff_matrix, duration=180)
        
        print(f"âš¡ ì„ì‹œ ì¡°ì •: {len(weakest_players)}ëª…ì—ê²Œ ë²„í”„ ì ìš©")
    
    def trigger_cooperation_event(self):
        """í˜‘ë ¥ ì´‰ì§„ ì´ë²¤íŠ¸ ë°œìƒ"""
        
        cooperation_events = [
            "diplomatic_summit",    # ì™¸êµ ì •ìƒíšŒë‹´
            "trade_festival",      # ë¬´ì—­ ì¶•ì œ
            "alliance_bonus",      # ë™ë§¹ ë³´ë„ˆìŠ¤
            "shared_victory"       # ê³µë™ ìŠ¹ë¦¬ ì¡°ê±´
        ]
        
        selected_event = np.random.choice(cooperation_events)
        self.activate_special_event(selected_event)
        
        print(f"ğŸ¤ í˜‘ë ¥ ì´ë²¤íŠ¸ ë°œìƒ: {selected_event}")

class PredictiveBalancer:
    """ì˜ˆì¸¡ì  ë°¸ëŸ°ì‹± ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.ml_model = self.load_balance_prediction_model()
        self.prediction_horizon = 300  # 5ë¶„ í›„ ì˜ˆì¸¡
        
    def predict_future_balance(self, 
                             current_state: Dict,
                             time_horizon: int = 300) -> BalanceMetrics:
        """ë¯¸ë˜ ë°¸ëŸ°ìŠ¤ ìƒíƒœ ì˜ˆì¸¡"""
        
        # í˜„ì¬ ìƒíƒœë¥¼ íŠ¹ì„± ë²¡í„°ë¡œ ë³€í™˜
        features = self.extract_features(current_state)
        
        # ML ëª¨ë¸ë¡œ ë¯¸ë˜ ìƒíƒœ ì˜ˆì¸¡
        predicted_metrics = self.ml_model.predict(features, time_horizon)
        
        return BalanceMetrics(*predicted_metrics)
    
    def recommend_preemptive_actions(self, 
                                   predicted_balance: BalanceMetrics) -> List[str]:
        """ì˜ˆì¸¡ëœ ë¶ˆê· í˜•ì— ëŒ€í•œ ì‚¬ì „ ëŒ€ì‘ ì¶”ì²œ"""
        
        recommendations = []
        
        if predicted_balance.frobenius_variance > 0.6:
            recommendations.append("í™˜ê²½ ë³€í™” ì¤€ë¹„")
        
        if predicted_balance.win_rate_deviation > 0.4:
            recommendations.append("ì•½í•œ íŒ€ ì§€ì› ì´ë²¤íŠ¸ ì¤€ë¹„")
        
        if predicted_balance.cooperation_index < 0.3:
            recommendations.append("í˜‘ë ¥ ì´‰ì§„ ì´ë²¤íŠ¸ ì˜ˆì•½")
        
        return recommendations

# ë©”ì¸ ì‹¤í–‰ ë£¨í”„
class BalancingOrchestrator:
    """ë°¸ëŸ°ì‹± ì‹œìŠ¤í…œ ì´ê´„ ê´€ë¦¬"""
    
    def __init__(self):
        self.dynamic_balancer = DynamicBalancer()
        self.predictive_balancer = PredictiveBalancer()
        self.running = False
        
    async def start_balancing_system(self):
        """ë°¸ëŸ°ì‹± ì‹œìŠ¤í…œ ì‹œì‘"""
        self.running = True
        
        while self.running:
            try:
                # í˜„ì¬ ë°¸ëŸ°ìŠ¤ ì²´í¬ ë° ì¡°ì •
                self.dynamic_balancer.run_balancing_cycle()
                
                # ë¯¸ë˜ ìƒíƒœ ì˜ˆì¸¡ ë° ì‚¬ì „ ëŒ€ì‘
                current_state = self.get_current_game_state()
                predicted_balance = self.predictive_balancer.predict_future_balance(
                    current_state
                )
                
                # ì˜ˆì¸¡ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­ ìƒì„±
                recommendations = self.predictive_balancer.recommend_preemptive_actions(
                    predicted_balance
                )
                
                if recommendations:
                    print(f"ğŸ”® ì˜ˆì¸¡ ê¶Œì¥ì‚¬í•­: {recommendations}")
                
                # 30ì´ˆ ëŒ€ê¸°
                await asyncio.sleep(30)
                
            except Exception as e:
                print(f"âŒ ë°¸ëŸ°ì‹± ì˜¤ë¥˜: {e}")
                await asyncio.sleep(60)  # ì˜¤ë¥˜ ì‹œ 1ë¶„ ëŒ€ê¸°
    
    def stop_balancing_system(self):
        """ë°¸ëŸ°ì‹± ì‹œìŠ¤í…œ ì¤‘ì§€"""
        self.running = False
        print("ğŸ›‘ ë™ì  ë°¸ëŸ°ì‹± ì‹œìŠ¤í…œ ì¤‘ì§€")

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    import asyncio
    
    orchestrator = BalancingOrchestrator()
    
    try:
        asyncio.run(orchestrator.start_balancing_system())
    except KeyboardInterrupt:
        orchestrator.stop_balancing_system()
```

---

**ë‹¤ìŒ ë‹¨ê³„**: JSON Schema ê¸°ë°˜ ë°ì´í„° êµ¬ì¡° êµ¬í˜„ ë° Redis ì—°ë™
