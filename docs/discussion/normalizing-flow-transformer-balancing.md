# Defense Allies Normalizing Flow + Transformer Î∞∏Îü∞Ïã± ÏãúÏä§ÌÖú

## üìã Î¨∏ÏÑú Ï†ïÎ≥¥
- **ÏûëÏÑ±Ïùº**: 2024ÎÖÑ
- **Î≤ÑÏ†Ñ**: v2.0 (Ï∞®ÏÑ∏ÎåÄ AI Î™®Îç∏)
- **Î™©Ï†Å**: Normalizing Flow + Transformer Í∏∞Î∞ò Í≤åÏûÑ Î∞∏Îü∞Ïã± ÏãúÏä§ÌÖú
- **ÌòÅÏã†**: ÏÑ∏Í≥Ñ ÏµúÏ¥à Flow-based Ïã§ÏãúÍ∞Ñ Í≤åÏûÑ Î∞∏Îü∞Ïã±

## üåä Normalizing Flow + Transformer Ìå®Îü¨Îã§ÏûÑ

### Í∏∞Ï°¥ Ïò§ÌÜ†Ïù∏ÏΩîÎçî vs ÏÉàÎ°úÏö¥ Ï†ëÍ∑ºÎ≤ï
```yaml
Ïò§ÌÜ†Ïù∏ÏΩîÎçî (1ÏÑ∏ÎåÄ):
  - Í≥†Ï†ïÎêú Ïû†Ïû¨ Í≥µÍ∞Ñ (3Ï∞®Ïõê)
  - Îã®Î∞©Ìñ• ÏïïÏ∂ï-Ïû¨Íµ¨ÏÑ±
  - Ï†ïÎ≥¥ ÏÜêÏã§ Î∂àÍ∞ÄÌîº
  - ÌôïÎ•† Î∂ÑÌè¨ Î™®Îç∏ÎßÅ ÌïúÍ≥Ñ

Normalizing Flow + Transformer (2ÏÑ∏ÎåÄ):
  - Í∞ÄÏó≠Ï†Å Î≥ÄÌôò (Ï†ïÎ≥¥ ÏÜêÏã§ ÏóÜÏùå)
  - ÌôïÎ•† Î∂ÑÌè¨ ÏßÅÏ†ë Î™®Îç∏ÎßÅ
  - Ï°∞Í±¥Î∂Ä ÏÉùÏÑ± Í∞ÄÎä•
  - ÏãúÌÄÄÏä§ ÏùòÏ°¥ÏÑ± Î™®Îç∏ÎßÅ
  - Î∂àÌôïÏã§ÏÑ± Ï†ïÎüâÌôî
```

### ÌïµÏã¨ ÏïÑÏù¥ÎîîÏñ¥
```python
# Flow-based Î∞∏Îü∞Ïã± Ìå®Îü¨Îã§ÏûÑ
def flow_balancing_paradigm():
    """
    Input: Í≤åÏûÑ ÏÉÅÌÉú ÏãúÌÄÄÏä§ (ÏãúÍ∞ÑÏóê Îî∞Î•∏ Î≥ÄÌôî)
    ‚Üì
    Normalizing Flow: Î≥µÏû°Ìïú Í≤åÏûÑ Î∂ÑÌè¨ ‚Üí Îã®ÏàúÌïú Í∞ÄÏö∞ÏãúÏïà Î∂ÑÌè¨
    ‚Üì
    Transformer: ÏãúÌÄÄÏä§ ÏùòÏ°¥ÏÑ± Î∞è Ïñ¥ÌÖêÏÖò Î©îÏª§ÎãàÏ¶ò
    ‚Üì
    Inverse Flow: Îã®Ïàú Î∂ÑÌè¨ ‚Üí ÏµúÏ†ÅÌôîÎêú Í≤åÏûÑ Î∂ÑÌè¨
    ‚Üì
    Output: ÌôïÎ•†Ï†Å Î∞∏Îü∞Ïã± Í≤∞Í≥º (Î∂àÌôïÏã§ÏÑ± Ìè¨Ìï®)
    """
    pass
```

## üîÑ Normalizing Flow ÏïÑÌÇ§ÌÖçÏ≤ò

### Flow-based Í≤åÏûÑ ÏÉÅÌÉú Î≥ÄÌôò
```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.distributions import Normal
import numpy as np

class CouplingLayer(nn.Module):
    """Coupling Layer for Normalizing Flow"""

    def __init__(self, input_dim: int, hidden_dim: int = 256):
        super().__init__()
        self.input_dim = input_dim
        self.mask = self.create_mask()

        # Scale and Translation networks
        self.scale_net = nn.Sequential(
            nn.Linear(input_dim // 2, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim // 2),
            nn.Tanh()  # Bounded scaling
        )

        self.translate_net = nn.Sequential(
            nn.Linear(input_dim // 2, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim // 2)
        )

    def create_mask(self):
        """Create alternating mask for coupling"""
        mask = torch.zeros(self.input_dim)
        mask[::2] = 1  # Every other dimension
        return mask

    def forward(self, x, reverse=False):
        """Forward/Inverse transformation"""
        mask = self.mask.to(x.device)

        if not reverse:
            # Forward: x -> z
            x_masked = x * mask
            x_unmasked = x * (1 - mask)

            scale = self.scale_net(x_masked)
            translate = self.translate_net(x_masked)

            z_unmasked = x_unmasked * torch.exp(scale) + translate
            z = x_masked + z_unmasked * (1 - mask)

            log_det = scale.sum(dim=-1)
            return z, log_det
        else:
            # Inverse: z -> x
            z_masked = x * mask
            z_unmasked = x * (1 - mask)

            scale = self.scale_net(z_masked)
            translate = self.translate_net(z_masked)

            x_unmasked = (z_unmasked - translate) * torch.exp(-scale)
            x = z_masked + x_unmasked * (1 - mask)

            log_det = -scale.sum(dim=-1)
            return x, log_det

class GameStateFlow(nn.Module):
    """Normalizing Flow for Game State Distribution"""

    def __init__(self, game_state_dim: int = 648, num_layers: int = 8):
        super().__init__()
        self.game_state_dim = game_state_dim
        self.num_layers = num_layers

        # Stack of coupling layers
        self.layers = nn.ModuleList([
            CouplingLayer(game_state_dim) for _ in range(num_layers)
        ])

        # Base distribution (standard Gaussian)
        self.base_dist = Normal(
            torch.zeros(game_state_dim),
            torch.ones(game_state_dim)
        )

    def forward(self, x):
        """Transform game state to base distribution"""
        log_det_total = 0
        z = x

        for layer in self.layers:
            z, log_det = layer(z, reverse=False)
            log_det_total += log_det

        # Calculate log probability
        log_prob_base = self.base_dist.log_prob(z).sum(dim=-1)
        log_prob = log_prob_base + log_det_total

        return z, log_prob

    def inverse(self, z):
        """Transform from base distribution to game state"""
        log_det_total = 0
        x = z

        # Reverse order for inverse
        for layer in reversed(self.layers):
            x, log_det = layer(x, reverse=True)
            log_det_total += log_det

        return x, log_det_total

    def sample(self, num_samples: int, device='cpu'):
        """Sample from learned game state distribution"""
        z = self.base_dist.sample((num_samples,)).to(device)
        x, _ = self.inverse(z)
        return x

class ConditionalGameFlow(nn.Module):
    """Conditional Flow for Context-aware Balancing"""

    def __init__(self, game_state_dim: int = 648, context_dim: int = 64):
        super().__init__()
        self.context_dim = context_dim

        # Context encoder
        self.context_encoder = nn.Sequential(
            nn.Linear(context_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 256),
            nn.ReLU(),
            nn.Linear(256, 128)
        )

        # Conditional coupling layers
        self.layers = nn.ModuleList([
            ConditionalCouplingLayer(game_state_dim, 128)
            for _ in range(8)
        ])

        self.base_dist = Normal(
            torch.zeros(game_state_dim),
            torch.ones(game_state_dim)
        )

    def forward(self, x, context):
        """Conditional transformation"""
        context_encoded = self.context_encoder(context)

        log_det_total = 0
        z = x

        for layer in self.layers:
            z, log_det = layer(z, context_encoded, reverse=False)
            log_det_total += log_det

        log_prob_base = self.base_dist.log_prob(z).sum(dim=-1)
        log_prob = log_prob_base + log_det_total

        return z, log_prob

    def conditional_sample(self, context, num_samples: int = 1):
        """Sample conditioned on context (game situation)"""
        context_encoded = self.context_encoder(context)

        z = self.base_dist.sample((num_samples,)).to(context.device)
        x = z

        for layer in reversed(self.layers):
            x, _ = layer(x, context_encoded, reverse=True)

        return x

class ConditionalCouplingLayer(nn.Module):
    """Context-aware Coupling Layer"""

    def __init__(self, input_dim: int, context_dim: int):
        super().__init__()
        self.input_dim = input_dim
        self.context_dim = context_dim
        self.mask = self.create_mask()

        # Context-conditioned networks
        self.scale_net = nn.Sequential(
            nn.Linear(input_dim // 2 + context_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, input_dim // 2),
            nn.Tanh()
        )

        self.translate_net = nn.Sequential(
            nn.Linear(input_dim // 2 + context_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, input_dim // 2)
        )

    def create_mask(self):
        mask = torch.zeros(self.input_dim)
        mask[::2] = 1
        return mask

    def forward(self, x, context, reverse=False):
        """Context-conditioned transformation"""
        mask = self.mask.to(x.device)

        if not reverse:
            x_masked = x * mask
            x_unmasked = x * (1 - mask)

            # Concatenate with context
            scale_input = torch.cat([x_masked, context], dim=-1)
            translate_input = torch.cat([x_masked, context], dim=-1)

            scale = self.scale_net(scale_input)
            translate = self.translate_net(translate_input)

            z_unmasked = x_unmasked * torch.exp(scale) + translate
            z = x_masked + z_unmasked * (1 - mask)

            log_det = scale.sum(dim=-1)
            return z, log_det
        else:
            z_masked = x * mask
            z_unmasked = x * (1 - mask)

            scale_input = torch.cat([z_masked, context], dim=-1)
            translate_input = torch.cat([z_masked, context], dim=-1)

            scale = self.scale_net(scale_input)
            translate = self.translate_net(translate_input)

            x_unmasked = (z_unmasked - translate) * torch.exp(-scale)
            x = z_masked + x_unmasked * (1 - mask)

            log_det = -scale.sum(dim=-1)
            return x, log_det
```

## ü§ñ Transformer ÏãúÌÄÄÏä§ Î™®Îç∏ÎßÅ

### Í≤åÏûÑ ÏÉÅÌÉú ÏãúÌÄÄÏä§ Transformer
```python
class GameSequenceTransformer(nn.Module):
    """Transformer for Game State Sequence Modeling"""

    def __init__(self,
                 game_state_dim: int = 648,
                 d_model: int = 512,
                 nhead: int = 8,
                 num_layers: int = 6,
                 max_seq_len: int = 100):
        super().__init__()

        self.d_model = d_model
        self.max_seq_len = max_seq_len

        # Input projection
        self.input_projection = nn.Linear(game_state_dim, d_model)

        # Positional encoding
        self.pos_encoding = PositionalEncoding(d_model, max_seq_len)

        # Transformer encoder
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=2048,
            dropout=0.1,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)

        # Output heads
        self.balance_head = nn.Linear(d_model, 3)  # 3D balance vector
        self.uncertainty_head = nn.Linear(d_model, 3)  # Uncertainty estimation
        self.next_state_head = nn.Linear(d_model, game_state_dim)  # Next state prediction

    def forward(self, game_sequence, mask=None):
        """Process game state sequence"""
        batch_size, seq_len, _ = game_sequence.shape

        # Project to model dimension
        x = self.input_projection(game_sequence)

        # Add positional encoding
        x = self.pos_encoding(x)

        # Transformer encoding
        if mask is not None:
            # Create attention mask
            attn_mask = self.create_attention_mask(mask)
        else:
            attn_mask = None

        encoded = self.transformer(x, src_key_padding_mask=attn_mask)

        # Use last token for predictions
        last_hidden = encoded[:, -1, :]

        # Multiple heads
        balance_vector = self.balance_head(last_hidden)
        uncertainty = torch.exp(self.uncertainty_head(last_hidden))  # Positive uncertainty
        next_state = self.next_state_head(last_hidden)

        return {
            'balance_vector': balance_vector,
            'uncertainty': uncertainty,
            'next_state_prediction': next_state,
            'sequence_encoding': encoded
        }

    def create_attention_mask(self, padding_mask):
        """Create attention mask for variable length sequences"""
        return padding_mask

class PositionalEncoding(nn.Module):
    """Sinusoidal Positional Encoding"""

    def __init__(self, d_model: int, max_len: int = 5000):
        super().__init__()

        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)

        div_term = torch.exp(torch.arange(0, d_model, 2).float() *
                           (-np.log(10000.0) / d_model))

        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)

        self.register_buffer('pe', pe)

    def forward(self, x):
        return x + self.pe[:x.size(1), :].transpose(0, 1)

class MultiHeadAttentionBalancer(nn.Module):
    """Multi-Head Attention for Balance Relationships"""

    def __init__(self, d_model: int = 512, num_heads: int = 8):
        super().__init__()
        self.d_model = d_model
        self.num_heads = num_heads
        self.head_dim = d_model // num_heads

        self.q_linear = nn.Linear(d_model, d_model)
        self.k_linear = nn.Linear(d_model, d_model)
        self.v_linear = nn.Linear(d_model, d_model)
        self.out_linear = nn.Linear(d_model, d_model)

        self.balance_weights = nn.Parameter(torch.randn(num_heads, 1))

    def forward(self, tower_states, race_states, environment_states):
        """Attention between towers, races, and environment"""
        batch_size = tower_states.size(0)

        # Compute Q, K, V
        Q = self.q_linear(tower_states).view(batch_size, -1, self.num_heads, self.head_dim)
        K = self.k_linear(race_states).view(batch_size, -1, self.num_heads, self.head_dim)
        V = self.v_linear(environment_states).view(batch_size, -1, self.num_heads, self.head_dim)

        # Transpose for attention computation
        Q = Q.transpose(1, 2)  # (batch, heads, seq, head_dim)
        K = K.transpose(1, 2)
        V = V.transpose(1, 2)

        # Scaled dot-product attention
        scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.head_dim)
        attention_weights = F.softmax(scores, dim=-1)

        # Apply attention to values
        attended = torch.matmul(attention_weights, V)

        # Concatenate heads
        attended = attended.transpose(1, 2).contiguous().view(
            batch_size, -1, self.d_model
        )

        # Final linear transformation
        output = self.out_linear(attended)

        # Balance-aware weighting
        balance_weighted = output * self.balance_weights.view(1, 1, -1)

        return balance_weighted, attention_weights
```

## üåä ÌÜµÌï© Flow-Transformer ÏãúÏä§ÌÖú

### ÏôÑÏ†ÑÌïú Î∞∏Îü∞Ïã± ÏïÑÌÇ§ÌÖçÏ≤ò
```python
class FlowTransformerBalancer(nn.Module):
    """Complete Flow + Transformer Balancing System"""

    def __init__(self,
                 game_state_dim: int = 648,
                 context_dim: int = 64,
                 sequence_length: int = 50):
        super().__init__()

        # Normalizing Flow components
        self.game_flow = ConditionalGameFlow(game_state_dim, context_dim)

        # Transformer components
        self.sequence_transformer = GameSequenceTransformer(
            game_state_dim=game_state_dim,
            max_seq_len=sequence_length
        )

        # Attention-based balancer
        self.attention_balancer = MultiHeadAttentionBalancer()

        # Context encoder for flow conditioning
        self.context_encoder = nn.Sequential(
            nn.Linear(64, 128),  # Environment + player state
            nn.ReLU(),
            nn.Linear(128, context_dim)
        )

        # Uncertainty quantification
        self.uncertainty_estimator = nn.Sequential(
            nn.Linear(game_state_dim + 3, 256),  # State + balance vector
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 1),
            nn.Sigmoid()  # Uncertainty score [0, 1]
        )

    def forward(self, game_sequence, environment_context, player_context):
        """Complete forward pass"""
        batch_size, seq_len, state_dim = game_sequence.shape

        # 1. Encode context
        full_context = torch.cat([environment_context, player_context], dim=-1)
        encoded_context = self.context_encoder(full_context)

        # 2. Transformer sequence processing
        transformer_output = self.sequence_transformer(game_sequence)
        balance_vector = transformer_output['balance_vector']
        sequence_encoding = transformer_output['sequence_encoding']

        # 3. Flow-based distribution modeling
        current_state = game_sequence[:, -1, :]  # Last state in sequence
        z, log_prob = self.game_flow(current_state, encoded_context)

        # 4. Generate balanced state
        balanced_state = self.game_flow.conditional_sample(
            encoded_context, num_samples=1
        ).squeeze(1)

        # 5. Uncertainty estimation
        uncertainty_input = torch.cat([current_state, balance_vector], dim=-1)
        uncertainty_score = self.uncertainty_estimator(uncertainty_input)

        return {
            'balanced_state': balanced_state,
            'balance_vector': balance_vector,
            'uncertainty_score': uncertainty_score,
            'log_probability': log_prob,
            'latent_representation': z,
            'sequence_encoding': sequence_encoding
        }

    def sample_balanced_states(self, context, num_samples: int = 10):
        """Sample multiple balanced states with uncertainty"""
        encoded_context = self.context_encoder(context)

        # Sample from flow
        samples = self.game_flow.conditional_sample(
            encoded_context, num_samples=num_samples
        )

        # Estimate uncertainty for each sample
        uncertainties = []
        for sample in samples:
            # Dummy balance vector for uncertainty estimation
            dummy_balance = torch.zeros(3).to(sample.device)
            uncertainty_input = torch.cat([sample, dummy_balance], dim=-1)
            uncertainty = self.uncertainty_estimator(uncertainty_input.unsqueeze(0))
            uncertainties.append(uncertainty.item())

        return samples, uncertainties

    def get_attention_insights(self, tower_states, race_states, env_states):
        """Get interpretable attention weights"""
        balanced_output, attention_weights = self.attention_balancer(
            tower_states, race_states, env_states
        )

        # Analyze attention patterns
        attention_insights = {
            'tower_race_attention': attention_weights.mean(dim=1),  # Average over heads
            'dominant_relationships': attention_weights.max(dim=-1)[1],
            'attention_entropy': self.calculate_attention_entropy(attention_weights)
        }

        return balanced_output, attention_insights

    def calculate_attention_entropy(self, attention_weights):
        """Calculate entropy of attention distribution"""
        # Avoid log(0) by adding small epsilon
        eps = 1e-8
        log_attention = torch.log(attention_weights + eps)
        entropy = -(attention_weights * log_attention).sum(dim=-1)
        return entropy

# Training and Inference
class FlowTransformerTrainer:
    """Training system for Flow + Transformer"""

    def __init__(self, model: FlowTransformerBalancer):
        self.model = model
        self.optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)

    def train_step(self, batch):
        """Single training step"""
        game_sequences = batch['sequences']
        env_context = batch['environment']
        player_context = batch['players']
        target_balance = batch['target_balance']

        # Forward pass
        output = self.model(game_sequences, env_context, player_context)

        # Multiple loss components
        losses = self.calculate_losses(output, target_balance, game_sequences)
        total_loss = sum(losses.values())

        # Backward pass
        self.optimizer.zero_grad()
        total_loss.backward()
        self.optimizer.step()

        return losses

    def calculate_losses(self, output, target_balance, sequences):
        """Multi-component loss function"""

        # 1. Balance vector loss
        balance_loss = F.mse_loss(output['balance_vector'], target_balance)

        # 2. Flow likelihood loss (maximize probability of good states)
        likelihood_loss = -output['log_probability'].mean()

        # 3. Uncertainty calibration loss
        uncertainty_loss = self.calibration_loss(
            output['uncertainty_score'],
            output['balanced_state'],
            sequences[:, -1, :]  # Current state
        )

        # 4. Sequence consistency loss
        consistency_loss = self.sequence_consistency_loss(
            output['sequence_encoding'],
            sequences
        )

        return {
            'balance_loss': balance_loss * 1.0,
            'likelihood_loss': likelihood_loss * 0.5,
            'uncertainty_loss': uncertainty_loss * 0.3,
            'consistency_loss': consistency_loss * 0.2
        }

    def calibration_loss(self, uncertainty, balanced_state, current_state):
        """Uncertainty calibration loss"""
        state_difference = F.mse_loss(balanced_state, current_state, reduction='none')
        state_difference = state_difference.mean(dim=-1)

        # Uncertainty should correlate with state difference
        target_uncertainty = torch.sigmoid(state_difference)
        return F.mse_loss(uncertainty.squeeze(), target_uncertainty)

    def sequence_consistency_loss(self, encoding, sequences):
        """Sequence consistency loss"""
        # Predict next state from encoding
        predicted_next = self.model.sequence_transformer.next_state_head(
            encoding[:, -1, :]
        )

        # Compare with actual next state (if available)
        if sequences.size(1) > 1:
            actual_current = sequences[:, -1, :]
            return F.mse_loss(predicted_next, actual_current)
        else:
            return torch.tensor(0.0, device=encoding.device)
```

## üöÄ Ïã§ÏãúÍ∞Ñ Ï∂îÎ°† Î∞è Î∂àÌôïÏã§ÏÑ± Ï†ïÎüâÌôî

### Ïã§ÏãúÍ∞Ñ Î∞∏Îü∞Ïã± ÏóîÏßÑ
```python
class RealTimeFlowBalancer:
    """Ïã§ÏãúÍ∞Ñ Flow + Transformer Î∞∏Îü∞Ïã± ÏóîÏßÑ"""

    def __init__(self, model_path: str):
        self.model = FlowTransformerBalancer()
        self.load_model(model_path)
        self.model.eval()

        # Ïã§ÏãúÍ∞Ñ Ï≤òÎ¶¨Î•º ÏúÑÌïú Î≤ÑÌçº
        self.sequence_buffer = []
        self.max_sequence_length = 50

        # Î∂àÌôïÏã§ÏÑ± ÏûÑÍ≥ÑÍ∞í
        self.uncertainty_threshold = 0.7
        self.confidence_threshold = 0.8

        # ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ
        self.inference_times = []
        self.uncertainty_history = []

    def real_time_balance(self, current_game_state: Dict) -> Dict:
        """Ïã§ÏãúÍ∞Ñ Í≤åÏûÑ Î∞∏Îü∞Ïã±"""
        start_time = time.time()

        # 1. Í≤åÏûÑ ÏÉÅÌÉúÎ•º ÏãúÌÄÄÏä§ Î≤ÑÌçºÏóê Ï∂îÍ∞Ä
        self.update_sequence_buffer(current_game_state)

        # 2. Ïª®ÌÖçÏä§Ìä∏ Ïù∏ÏΩîÎî©
        context = self.encode_game_context(current_game_state)

        # 3. Îã§Ï§ë ÏÉòÌîåÎßÅÏúºÎ°ú Î∂àÌôïÏã§ÏÑ± Ï†ïÎüâÌôî
        balanced_samples, uncertainties = self.sample_with_uncertainty(
            context, num_samples=10
        )

        # 4. ÏµúÏ†Å ÏÉòÌîå ÏÑ†ÌÉù
        best_sample, confidence = self.select_best_sample(
            balanced_samples, uncertainties
        )

        # 5. Ïñ¥ÌÖêÏÖò Î∂ÑÏÑùÏúºÎ°ú Ìï¥ÏÑù Í∞ÄÎä•ÏÑ± Ï†úÍ≥µ
        attention_insights = self.analyze_attention_patterns(
            current_game_state, context
        )

        # 6. ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ
        inference_time = time.time() - start_time
        self.inference_times.append(inference_time)
        self.uncertainty_history.append(1 - confidence)

        return {
            'balanced_state': best_sample,
            'confidence': confidence,
            'uncertainty_score': 1 - confidence,
            'attention_insights': attention_insights,
            'inference_time': inference_time,
            'requires_human_review': confidence < self.confidence_threshold,
            'alternative_samples': balanced_samples[:3]  # Top 3 alternatives
        }

    def sample_with_uncertainty(self, context: torch.Tensor,
                               num_samples: int = 10) -> Tuple[List, List]:
        """Î∂àÌôïÏã§ÏÑ±ÏùÑ Í≥†Î†§Ìïú Îã§Ï§ë ÏÉòÌîåÎßÅ"""

        with torch.no_grad():
            # FlowÏóêÏÑú Îã§Ï§ë ÏÉòÌîå ÏÉùÏÑ±
            samples, sample_uncertainties = self.model.sample_balanced_states(
                context, num_samples=num_samples
            )

            # Í∞Å ÏÉòÌîåÏùò ÌíàÏßà ÌèâÍ∞Ä
            sample_qualities = []
            for sample in samples:
                quality = self.evaluate_sample_quality(sample, context)
                sample_qualities.append(quality)

            # Î∂àÌôïÏã§ÏÑ±Í≥º ÌíàÏßàÏùÑ Í≤∞Ìï©Ìïú Ï†êÏàò
            combined_scores = []
            for quality, uncertainty in zip(sample_qualities, sample_uncertainties):
                # ÎÜíÏùÄ ÌíàÏßà, ÎÇÆÏùÄ Î∂àÌôïÏã§ÏÑ±Ïù¥ Ï¢ãÏùå
                score = quality * (1 - uncertainty)
                combined_scores.append(score)

            # Ï†êÏàò ÏàúÏúºÎ°ú Ï†ïÎ†¨
            sorted_indices = np.argsort(combined_scores)[::-1]
            sorted_samples = [samples[i] for i in sorted_indices]
            sorted_uncertainties = [sample_uncertainties[i] for i in sorted_indices]

            return sorted_samples, sorted_uncertainties

    def evaluate_sample_quality(self, sample: torch.Tensor,
                               context: torch.Tensor) -> float:
        """ÏÉòÌîå ÌíàÏßà ÌèâÍ∞Ä"""

        # 1. Îß§Ìä∏Î¶≠Ïä§ Ï†úÏïΩ Ï°∞Í±¥ ÌôïÏù∏
        matrices = sample.view(-1, 2, 2)  # Reshape to matrices
        constraint_score = self.check_matrix_constraints(matrices)

        # 2. Ïª®ÌÖçÏä§Ìä∏ Ï†ÅÌï©ÏÑ± ÌôïÏù∏
        context_score = self.check_context_fitness(sample, context)

        # 3. Î∞∏Îü∞Ïä§ ÌíàÏßà ÌôïÏù∏
        balance_score = self.check_balance_quality(matrices)

        # Í∞ÄÏ§ë ÌèâÍ∑†
        quality = (
            constraint_score * 0.4 +
            context_score * 0.3 +
            balance_score * 0.3
        )

        return quality

    def check_matrix_constraints(self, matrices: torch.Tensor) -> float:
        """Îß§Ìä∏Î¶≠Ïä§ Ï†úÏïΩ Ï°∞Í±¥ ÌôïÏù∏"""

        scores = []
        for matrix in matrices:
            # ÌîÑÎ°úÎ≤†ÎãàÏö∞Ïä§ ÎÖ∏Î¶Ñ Ï≤¥ÌÅ¨
            norm = torch.norm(matrix, 'fro')
            norm_score = 1.0 if 1.8 <= norm <= 2.2 else 0.5

            # ÌñâÎ†¨Ïãù Ï≤¥ÌÅ¨
            det = torch.det(matrix)
            det_score = 1.0 if 0.0 <= det <= 2.0 else 0.5

            # ÎåÄÍ∞ÅÌï© Ï≤¥ÌÅ¨
            trace = torch.trace(matrix)
            trace_score = 1.0 if 1.5 <= trace <= 2.5 else 0.5

            matrix_score = (norm_score + det_score + trace_score) / 3
            scores.append(matrix_score)

        return np.mean(scores)

    def select_best_sample(self, samples: List, uncertainties: List) -> Tuple[torch.Tensor, float]:
        """ÏµúÏ†Å ÏÉòÌîå ÏÑ†ÌÉù"""

        # Ïù¥ÎØ∏ Ï†ïÎ†¨Îêú ÏÉÅÌÉúÏù¥ÎØÄÎ°ú Ï≤´ Î≤àÏß∏Í∞Ä ÏµúÍ≥†
        best_sample = samples[0]
        best_uncertainty = uncertainties[0]

        # Ïã†Î¢∞ÎèÑ Í≥ÑÏÇ∞ (1 - Î∂àÌôïÏã§ÏÑ±)
        confidence = 1 - best_uncertainty

        # Ï∂îÍ∞Ä Í≤ÄÏ¶ù: Îã§Î•∏ ÏÉòÌîåÎì§Í≥ºÏùò ÏùºÍ¥ÄÏÑ± ÌôïÏù∏
        if len(samples) > 1:
            consistency = self.check_sample_consistency(samples[:3])
            confidence *= consistency

        return best_sample, confidence

    def check_sample_consistency(self, top_samples: List) -> float:
        """ÏÉÅÏúÑ ÏÉòÌîåÎì§ Í∞ÑÏùò ÏùºÍ¥ÄÏÑ± ÌôïÏù∏"""

        if len(top_samples) < 2:
            return 1.0

        # ÏÉòÌîåÎì§ Í∞ÑÏùò ÌèâÍ∑† Í±∞Î¶¨ Í≥ÑÏÇ∞
        distances = []
        for i in range(len(top_samples)):
            for j in range(i + 1, len(top_samples)):
                dist = torch.norm(top_samples[i] - top_samples[j], p=2)
                distances.append(dist.item())

        avg_distance = np.mean(distances)

        # Í±∞Î¶¨Í∞Ä ÏûëÏùÑÏàòÎ°ù ÏùºÍ¥ÄÏÑ±Ïù¥ ÎÜíÏùå
        consistency = 1.0 / (1.0 + avg_distance)

        return consistency

    def analyze_attention_patterns(self, game_state: Dict,
                                 context: torch.Tensor) -> Dict:
        """Ïñ¥ÌÖêÏÖò Ìå®ÌÑ¥ Î∂ÑÏÑùÏúºÎ°ú Ìï¥ÏÑù Í∞ÄÎä•ÏÑ± Ï†úÍ≥µ"""

        # Í≤åÏûÑ ÏÉÅÌÉúÎ•º Íµ¨ÏÑ± ÏöîÏÜåÎ≥ÑÎ°ú Î∂ÑÎ¶¨
        tower_states = self.extract_tower_states(game_state)
        race_states = self.extract_race_states(game_state)
        env_states = self.extract_environment_states(game_state)

        # Ïñ¥ÌÖêÏÖò Î∂ÑÏÑù
        with torch.no_grad():
            balanced_output, attention_insights = self.model.get_attention_insights(
                tower_states, race_states, env_states
            )

        # Ìï¥ÏÑù Í∞ÄÎä•Ìïú ÌòïÌÉúÎ°ú Î≥ÄÌôò
        interpretable_insights = {
            'dominant_tower_race_pairs': self.interpret_attention_weights(
                attention_insights['tower_race_attention']
            ),
            'attention_focus': self.get_attention_focus(
                attention_insights['attention_entropy']
            ),
            'balance_reasoning': self.generate_balance_reasoning(
                attention_insights
            )
        }

        return interpretable_insights

    def interpret_attention_weights(self, attention_weights: torch.Tensor) -> List[Dict]:
        """Ïñ¥ÌÖêÏÖò Í∞ÄÏ§ëÏπòÎ•º Ìï¥ÏÑù Í∞ÄÎä•Ìïú ÌòïÌÉúÎ°ú Î≥ÄÌôò"""

        # ÏÉÅÏúÑ 5Í∞ú Ïñ¥ÌÖêÏÖò Í¥ÄÍ≥Ñ Ï∂îÏ∂ú
        top_k = 5
        flat_weights = attention_weights.flatten()
        top_indices = torch.topk(flat_weights, top_k).indices

        interpretations = []
        for idx in top_indices:
            # 2D Ïù∏Îç±Ïä§Î°ú Î≥ÄÌôò
            tower_idx = idx // attention_weights.size(1)
            race_idx = idx % attention_weights.size(1)
            weight = flat_weights[idx].item()

            interpretation = {
                'tower_index': tower_idx.item(),
                'race_index': race_idx.item(),
                'attention_weight': weight,
                'relationship_strength': 'strong' if weight > 0.7 else 'moderate' if weight > 0.4 else 'weak'
            }
            interpretations.append(interpretation)

        return interpretations

    def generate_balance_reasoning(self, attention_insights: Dict) -> str:
        """Î∞∏Îü∞Ïã± Ï∂îÎ°† Í≥ºÏ†ïÏùÑ ÏûêÏó∞Ïñ¥Î°ú ÏÑ§Î™Ö"""

        reasoning_parts = []

        # Ïñ¥ÌÖêÏÖò ÏóîÌä∏Î°úÌîº Î∂ÑÏÑù
        entropy = attention_insights['attention_entropy'].mean().item()
        if entropy > 2.0:
            reasoning_parts.append("Î≥µÏû°Ìïú Îã§Ï§ë ÏöîÏÜå ÏÉÅÌò∏ÏûëÏö©Ïù¥ Í∞êÏßÄÎê®")
        elif entropy > 1.0:
            reasoning_parts.append("Ï§ëÍ∞Ñ ÏàòÏ§ÄÏùò Ï†ÑÎûµÏ†Å Î≥µÏû°ÏÑ±")
        else:
            reasoning_parts.append("Îã®ÏàúÌïòÍ≥† ÏßëÏ§ëÎêú Ï†ÑÎûµ Ìå®ÌÑ¥")

        # ÏßÄÎ∞∞Ï†Å Í¥ÄÍ≥Ñ Î∂ÑÏÑù
        dominant_relationships = attention_insights['dominant_relationships']
        unique_relationships = len(torch.unique(dominant_relationships))

        if unique_relationships > 5:
            reasoning_parts.append("Îã§ÏñëÌïú Ï¢ÖÏ°±-ÌÉÄÏõå Ï°∞Ìï©Ïù¥ ÌôúÏö©Îê®")
        else:
            reasoning_parts.append("ÌäπÏ†ï Ï°∞Ìï©Ïóê ÏßëÏ§ëÎêú Ï†ÑÎûµ")

        return " | ".join(reasoning_parts)

class UncertaintyQuantifier:
    """Î∂àÌôïÏã§ÏÑ± Ï†ïÎüâÌôî Ï†ÑÎ¨∏ ÌÅ¥ÎûòÏä§"""

    def __init__(self):
        self.calibration_data = []
        self.uncertainty_types = [
            'aleatoric',    # Îç∞Ïù¥ÌÑ∞ Í≥†Ïú† Î∂àÌôïÏã§ÏÑ±
            'epistemic',    # Î™®Îç∏ ÏßÄÏãù Î∂àÌôïÏã§ÏÑ±
            'distributional' # Î∂ÑÌè¨ Ïô∏ Îç∞Ïù¥ÌÑ∞ Î∂àÌôïÏã§ÏÑ±
        ]

    def quantify_uncertainty(self, model_output: Dict,
                           game_context: Dict) -> Dict[str, float]:
        """Îã§Ï∞®Ïõê Î∂àÌôïÏã§ÏÑ± Ï†ïÎüâÌôî"""

        # 1. Aleatoric Î∂àÌôïÏã§ÏÑ± (Îç∞Ïù¥ÌÑ∞ Í≥†Ïú†)
        aleatoric = self.estimate_aleatoric_uncertainty(
            model_output['balanced_state'],
            game_context
        )

        # 2. Epistemic Î∂àÌôïÏã§ÏÑ± (Î™®Îç∏ ÏßÄÏãù)
        epistemic = self.estimate_epistemic_uncertainty(
            model_output['sequence_encoding'],
            model_output['latent_representation']
        )

        # 3. Distributional Î∂àÌôïÏã§ÏÑ± (Î∂ÑÌè¨ Ïô∏)
        distributional = self.estimate_distributional_uncertainty(
            model_output['log_probability']
        )

        # 4. Ï¢ÖÌï© Î∂àÌôïÏã§ÏÑ±
        total_uncertainty = self.combine_uncertainties(
            aleatoric, epistemic, distributional
        )

        return {
            'aleatoric_uncertainty': aleatoric,
            'epistemic_uncertainty': epistemic,
            'distributional_uncertainty': distributional,
            'total_uncertainty': total_uncertainty,
            'confidence_interval': self.calculate_confidence_interval(total_uncertainty),
            'reliability_score': 1 - total_uncertainty
        }

    def estimate_aleatoric_uncertainty(self, balanced_state: torch.Tensor,
                                     game_context: Dict) -> float:
        """Îç∞Ïù¥ÌÑ∞ Í≥†Ïú† Î∂àÌôïÏã§ÏÑ± Ï∂îÏ†ï"""

        # Í≤åÏûÑ ÏÉÅÌô©Ïùò Î≥µÏû°ÏÑ± Í∏∞Î∞ò Î∂àÌôïÏã§ÏÑ±
        complexity_factors = [
            len(game_context.get('active_players', [])),
            len(game_context.get('active_events', [])),
            game_context.get('game_progress', 0.5)
        ]

        complexity_score = np.mean(complexity_factors)

        # ÏÉÅÌÉú Î≥ÄÌôîÏùò ÌÅ¨Í∏∞
        if hasattr(self, 'previous_state'):
            state_change = torch.norm(balanced_state - self.previous_state).item()
            change_uncertainty = min(state_change / 10.0, 1.0)
        else:
            change_uncertainty = 0.5

        self.previous_state = balanced_state.clone()

        aleatoric = (complexity_score + change_uncertainty) / 2
        return min(aleatoric, 1.0)

    def estimate_epistemic_uncertainty(self, sequence_encoding: torch.Tensor,
                                     latent_representation: torch.Tensor) -> float:
        """Î™®Îç∏ ÏßÄÏãù Î∂àÌôïÏã§ÏÑ± Ï∂îÏ†ï"""

        # Ïû†Ïû¨ ÌëúÌòÑÏùò Î∂ÑÏÇ∞
        latent_variance = torch.var(latent_representation).item()

        # ÏãúÌÄÄÏä§ Ïù∏ÏΩîÎî©Ïùò ÏùºÍ¥ÄÏÑ±
        if sequence_encoding.size(1) > 1:
            encoding_consistency = torch.var(
                sequence_encoding, dim=1
            ).mean().item()
        else:
            encoding_consistency = 0.5

        # Î™®Îç∏ ÌôúÏÑ±ÌôîÏùò ÏóîÌä∏Î°úÌîº
        activation_entropy = self.calculate_activation_entropy(sequence_encoding)

        epistemic = (latent_variance + encoding_consistency + activation_entropy) / 3
        return min(epistemic, 1.0)

    def estimate_distributional_uncertainty(self, log_probability: torch.Tensor) -> float:
        """Î∂ÑÌè¨ Ïô∏ Î∂àÌôïÏã§ÏÑ± Ï∂îÏ†ï"""

        # Î°úÍ∑∏ ÌôïÎ•†Ïù¥ ÎÇÆÏùÑÏàòÎ°ù Î∂ÑÌè¨ Ïô∏ Í∞ÄÎä•ÏÑ± ÎÜíÏùå
        avg_log_prob = log_probability.mean().item()

        # Ï†ïÍ∑úÌôî (ÏùºÎ∞òÏ†ÅÏúºÎ°ú -10 ~ 0 Î≤îÏúÑ)
        normalized_prob = (avg_log_prob + 10) / 10
        distributional = 1 - max(0, min(1, normalized_prob))

        return distributional

    def calculate_activation_entropy(self, activations: torch.Tensor) -> float:
        """ÌôúÏÑ±Ìôî ÏóîÌä∏Î°úÌîº Í≥ÑÏÇ∞"""

        # ÌôúÏÑ±ÌôîÎ•º ÌôïÎ•† Î∂ÑÌè¨Î°ú Î≥ÄÌôò
        probs = F.softmax(activations.flatten(), dim=0)

        # ÏóîÌä∏Î°úÌîº Í≥ÑÏÇ∞
        log_probs = torch.log(probs + 1e-8)
        entropy = -(probs * log_probs).sum().item()

        # Ï†ïÍ∑úÌôî (ÏµúÎåÄ ÏóîÌä∏Î°úÌîºÎ°ú ÎÇòÎàî)
        max_entropy = np.log(len(probs))
        normalized_entropy = entropy / max_entropy

        return normalized_entropy

    def combine_uncertainties(self, aleatoric: float, epistemic: float,
                            distributional: float) -> float:
        """Î∂àÌôïÏã§ÏÑ±Îì§ÏùÑ Í≤∞Ìï©"""

        # Í∞ÄÏ§ë ÌèâÍ∑† (epistemicÏù¥ Í∞ÄÏû• Ï§ëÏöî)
        weights = [0.3, 0.5, 0.2]  # [aleatoric, epistemic, distributional]
        uncertainties = [aleatoric, epistemic, distributional]

        combined = sum(w * u for w, u in zip(weights, uncertainties))

        return min(combined, 1.0)

    def calculate_confidence_interval(self, uncertainty: float) -> Tuple[float, float]:
        """Ïã†Î¢∞ Íµ¨Í∞Ñ Í≥ÑÏÇ∞"""

        # Î∂àÌôïÏã§ÏÑ±ÏùÑ Ïã†Î¢∞ Íµ¨Í∞Ñ Ìè≠ÏúºÎ°ú Î≥ÄÌôò
        interval_width = uncertainty * 2.0  # ¬±uncertainty

        center = 0.5  # Ï§ëÏã¨Í∞í (Ï†ïÍ∑úÌôîÎêú Í≥µÍ∞ÑÏóêÏÑú)
        lower = max(0.0, center - interval_width / 2)
        upper = min(1.0, center + interval_width / 2)

        return (lower, upper)

class PerformanceMonitor:
    """Ïã§ÏãúÍ∞Ñ ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ"""

    def __init__(self):
        self.metrics_history = {
            'inference_time': [],
            'uncertainty_score': [],
            'confidence_score': [],
            'sample_quality': [],
            'attention_entropy': []
        }

        self.alert_thresholds = {
            'max_inference_time': 0.1,  # 100ms
            'min_confidence': 0.7,
            'max_uncertainty': 0.5
        }

    def update_metrics(self, inference_result: Dict):
        """Î©îÌä∏Î¶≠ ÏóÖÎç∞Ïù¥Ìä∏"""

        self.metrics_history['inference_time'].append(
            inference_result['inference_time']
        )
        self.metrics_history['uncertainty_score'].append(
            inference_result['uncertainty_score']
        )
        self.metrics_history['confidence_score'].append(
            inference_result['confidence']
        )

        # ÏµúÍ∑º 100Í∞ú Í∏∞Î°ùÎßå Ïú†ÏßÄ
        for key in self.metrics_history:
            if len(self.metrics_history[key]) > 100:
                self.metrics_history[key] = self.metrics_history[key][-100:]

    def check_alerts(self) -> List[str]:
        """ÏÑ±Îä• ÏïåÎ¶º ÌôïÏù∏"""

        alerts = []

        # ÏµúÍ∑º Ï∂îÎ°† ÏãúÍ∞Ñ ÌôïÏù∏
        if self.metrics_history['inference_time']:
            recent_time = self.metrics_history['inference_time'][-1]
            if recent_time > self.alert_thresholds['max_inference_time']:
                alerts.append(f"Ï∂îÎ°† ÏãúÍ∞Ñ Ï¥àÍ≥º: {recent_time:.3f}s")

        # ÏµúÍ∑º Ïã†Î¢∞ÎèÑ ÌôïÏù∏
        if self.metrics_history['confidence_score']:
            recent_confidence = self.metrics_history['confidence_score'][-1]
            if recent_confidence < self.alert_thresholds['min_confidence']:
                alerts.append(f"Ïã†Î¢∞ÎèÑ Î∂ÄÏ°±: {recent_confidence:.3f}")

        # ÌèâÍ∑† Î∂àÌôïÏã§ÏÑ± ÌôïÏù∏
        if len(self.metrics_history['uncertainty_score']) >= 10:
            avg_uncertainty = np.mean(self.metrics_history['uncertainty_score'][-10:])
            if avg_uncertainty > self.alert_thresholds['max_uncertainty']:
                alerts.append(f"Î∂àÌôïÏã§ÏÑ± Ï¶ùÍ∞Ä: {avg_uncertainty:.3f}")

        return alerts

    def generate_performance_report(self) -> Dict:
        """ÏÑ±Îä• Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±"""

        report = {}

        for metric_name, values in self.metrics_history.items():
            if values:
                report[metric_name] = {
                    'mean': np.mean(values),
                    'std': np.std(values),
                    'min': np.min(values),
                    'max': np.max(values),
                    'recent_trend': self.calculate_trend(values[-20:]) if len(values) >= 20 else 'insufficient_data'
                }

        return report

    def calculate_trend(self, values: List[float]) -> str:
        """Ìä∏Î†åÎìú Í≥ÑÏÇ∞"""

        if len(values) < 2:
            return 'insufficient_data'

        # ÏÑ†Ìòï ÌöåÍ∑ÄÎ°ú Ìä∏Î†åÎìú Í≥ÑÏÇ∞
        x = np.arange(len(values))
        slope = np.polyfit(x, values, 1)[0]

        if slope > 0.01:
            return 'increasing'
        elif slope < -0.01:
            return 'decreasing'
        else:
            return 'stable'

# ÏÇ¨Ïö© ÏòàÏãú
def main_flow_transformer_system():
    """Flow + Transformer ÏãúÏä§ÌÖú Î©îÏù∏ Ïã§Ìñâ"""

    print("üåä Defense Allies Flow + Transformer Î∞∏Îü∞Ïã± ÏãúÏä§ÌÖú")
    print("=" * 60)

    # 1. Ïã§ÏãúÍ∞Ñ Î∞∏Îü∞ÏÑú Ï¥àÍ∏∞Ìôî
    balancer = RealTimeFlowBalancer('flow_transformer_model.pth')
    uncertainty_quantifier = UncertaintyQuantifier()
    performance_monitor = PerformanceMonitor()

    # 2. ÏãúÎÆ¨Î†àÏù¥ÏÖò Í≤åÏûÑ ÏÉÅÌÉú
    game_state = {
        'tower_matrices': np.random.rand(20, 2, 2),
        'active_players': ['player1', 'player2', 'player3'],
        'game_progress': 0.6,
        'environment': {'time': 'day', 'weather': 'clear', 'terrain': 'forest'},
        'active_events': ['meteor_shower']
    }

    # 3. Ïã§ÏãúÍ∞Ñ Î∞∏Îü∞Ïã± Ïã§Ìñâ
    result = balancer.real_time_balance(game_state)

    # 4. Î∂àÌôïÏã§ÏÑ± Ï†ïÎüâÌôî
    uncertainty_analysis = uncertainty_quantifier.quantify_uncertainty(
        result, game_state
    )

    # 5. ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ
    performance_monitor.update_metrics(result)
    alerts = performance_monitor.check_alerts()

    # 6. Í≤∞Í≥º Ï∂úÎ†•
    print(f"\nüéØ Î∞∏Îü∞Ïã± Í≤∞Í≥º:")
    print(f"Ïã†Î¢∞ÎèÑ: {result['confidence']:.3f}")
    print(f"Î∂àÌôïÏã§ÏÑ±: {result['uncertainty_score']:.3f}")
    print(f"Ï∂îÎ°† ÏãúÍ∞Ñ: {result['inference_time']:.3f}Ï¥à")
    print(f"Ïù∏Í∞Ñ Í≤ÄÌÜ† ÌïÑÏöî: {'Ïòà' if result['requires_human_review'] else 'ÏïÑÎãàÏò§'}")

    print(f"\nüìä Î∂àÌôïÏã§ÏÑ± Î∂ÑÏÑù:")
    for key, value in uncertainty_analysis.items():
        if isinstance(value, (int, float)):
            print(f"{key}: {value:.3f}")

    print(f"\nüîç Ïñ¥ÌÖêÏÖò Ïù∏ÏÇ¨Ïù¥Ìä∏:")
    print(f"Î∞∏Îü∞Ïã± Ï∂îÎ°†: {result['attention_insights']['balance_reasoning']}")

    if alerts:
        print(f"\n‚ö†Ô∏è ÏÑ±Îä• ÏïåÎ¶º:")
        for alert in alerts:
            print(f"  - {alert}")

    print(f"\n‚úÖ Flow + Transformer Î∞∏Îü∞Ïã± ÏôÑÎ£å!")

if __name__ == "__main__":
    main_flow_transformer_system()
```

## üèÜ Flow + Transformer vs Ïò§ÌÜ†Ïù∏ÏΩîÎçî ÎπÑÍµê

### Í∏∞Ïà†Ï†Å Ïö∞ÏàòÏÑ±
```yaml
Ï†ïÎ≥¥ Î≥¥Ï°¥:
  Ïò§ÌÜ†Ïù∏ÏΩîÎçî: Ï†ïÎ≥¥ ÏÜêÏã§ Î∂àÍ∞ÄÌîº (ÏïïÏ∂ï Í≥ºÏ†ïÏóêÏÑú)
  Flow + Transformer: ÏôÑÏ†Ñ Í∞ÄÏó≠ Î≥ÄÌôò (Ï†ïÎ≥¥ ÏÜêÏã§ ÏóÜÏùå)

ÌôïÎ•† Î™®Îç∏ÎßÅ:
  Ïò§ÌÜ†Ïù∏ÏΩîÎçî: Ï†ê Ï∂îÏ†ï (Îã®Ïùº Í≤∞Í≥º)
  Flow + Transformer: ÌôïÎ•† Î∂ÑÌè¨ Î™®Îç∏ÎßÅ (Îã§Ï§ë Í≤∞Í≥º + Î∂àÌôïÏã§ÏÑ±)

ÏãúÌÄÄÏä§ Ï≤òÎ¶¨:
  Ïò§ÌÜ†Ïù∏ÏΩîÎçî: Îã®Ïùº ÏãúÏ†ê Ï≤òÎ¶¨
  Flow + Transformer: ÏãúÍ∞ÑÏ†Å ÏùòÏ°¥ÏÑ± Î™®Îç∏ÎßÅ

Ìï¥ÏÑù Í∞ÄÎä•ÏÑ±:
  Ïò§ÌÜ†Ïù∏ÏΩîÎçî: Î∏îÎûôÎ∞ïÏä§
  Flow + Transformer: Ïñ¥ÌÖêÏÖò Í∏∞Î∞ò Ìï¥ÏÑù Í∞ÄÎä•ÏÑ±
```

### Ïã§Ïö©Ï†Å Ïû•Ï†ê
```yaml
Î∂àÌôïÏã§ÏÑ± Ï†ïÎüâÌôî:
  - Aleatoric (Îç∞Ïù¥ÌÑ∞ Í≥†Ïú†)
  - Epistemic (Î™®Îç∏ ÏßÄÏãù)
  - Distributional (Î∂ÑÌè¨ Ïô∏)
  - Ïã†Î¢∞ Íµ¨Í∞Ñ Ï†úÍ≥µ

Îã§Ï§ë ÏÉòÌîåÎßÅ:
  - 10Í∞ú ÌõÑÎ≥¥ Ï§ë ÏµúÏ†Å ÏÑ†ÌÉù
  - ÎåÄÏïà ÏÜîÎ£®ÏÖò Ï†úÍ≥µ
  - ÏùºÍ¥ÄÏÑ± Í≤ÄÏ¶ù

Ïã§ÏãúÍ∞Ñ ÏÑ±Îä•:
  - 100ms Ïù¥Ìïò Ï∂îÎ°† ÏãúÍ∞Ñ
  - ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ Î∞è ÏïåÎ¶º
  - ÏûêÎèô ÌíàÏßà Í¥ÄÎ¶¨
```

### Í≤åÏûÑ ÏÇ∞ÏóÖ ÌòÅÏã†
```yaml
ÏÑ∏Í≥Ñ ÏµúÏ¥à:
  - Flow-based Í≤åÏûÑ Î∞∏Îü∞Ïã±
  - ÌôïÎ•†Ï†Å Î∞∏Îü∞Ïä§ Ï°∞Ï†ï
  - Î∂àÌôïÏã§ÏÑ± Í∏∞Î∞ò ÏùòÏÇ¨Í≤∞Ï†ï

Ïã§Ïö©Ï†Å Í∞ÄÏπò:
  - Ïù∏Í∞Ñ Í≤ÄÌÜ† ÌïÑÏöîÏÑ± ÏûêÎèô ÌåêÎã®
  - Îã§Ï§ë ÎåÄÏïà Ï†úÏãú
  - Ïã§ÏãúÍ∞Ñ ÏÑ±Îä• Î≥¥Ïû•
```

**Defense AlliesÎäî Ïù¥Ï†ú Ï∞®ÏÑ∏ÎåÄ AI Í∏∞Ïà†Î°ú Î¨¥Ïû•Ìïú ÏÑ∏Í≥Ñ ÏµúÍ≥† ÏàòÏ§ÄÏùò Î∞∏Îü∞Ïã± ÏãúÏä§ÌÖúÏùÑ Î≥¥Ïú†ÌñàÏäµÎãàÎã§!** üåäü§ñ

---

**Îã§Ïùå Îã®Í≥Ñ**: Diffusion Î™®Îç∏ Í∏∞Î∞ò Î∞∏Îü∞Ïã± ÏãúÏä§ÌÖú ÏÑ§Í≥Ñ Î∞è 3ÏÑ∏ÎåÄ AI ÌÜµÌï©
