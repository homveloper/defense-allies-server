# Defense Allies Normalizing Flow + Transformer ë°¸ëŸ°ì‹± ì‹œìŠ¤í…œ

## ğŸ“‹ ë¬¸ì„œ ì •ë³´
- **ì‘ì„±ì¼**: 2024ë…„
- **ë²„ì „**: v2.0 (ì°¨ì„¸ëŒ€ AI ëª¨ë¸)
- **ëª©ì **: Normalizing Flow + Transformer ê¸°ë°˜ ê²Œì„ ë°¸ëŸ°ì‹± ì‹œìŠ¤í…œ
- **í˜ì‹ **: ì„¸ê³„ ìµœì´ˆ Flow-based ì‹¤ì‹œê°„ ê²Œì„ ë°¸ëŸ°ì‹±

## ğŸŒŠ Normalizing Flow + Transformer íŒ¨ëŸ¬ë‹¤ì„

### ê¸°ì¡´ ì˜¤í† ì¸ì½”ë” vs ìƒˆë¡œìš´ ì ‘ê·¼ë²•
```yaml
ì˜¤í† ì¸ì½”ë” (1ì„¸ëŒ€):
  - ê³ ì •ëœ ì ì¬ ê³µê°„ (3ì°¨ì›)
  - ë‹¨ë°©í–¥ ì••ì¶•-ì¬êµ¬ì„±
  - ì •ë³´ ì†ì‹¤ ë¶ˆê°€í”¼
  - í™•ë¥  ë¶„í¬ ëª¨ë¸ë§ í•œê³„

Normalizing Flow + Transformer (2ì„¸ëŒ€):
  - ê°€ì—­ì  ë³€í™˜ (ì •ë³´ ì†ì‹¤ ì—†ìŒ)
  - í™•ë¥  ë¶„í¬ ì§ì ‘ ëª¨ë¸ë§
  - ì¡°ê±´ë¶€ ìƒì„± ê°€ëŠ¥
  - ì‹œí€€ìŠ¤ ì˜ì¡´ì„± ëª¨ë¸ë§
  - ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”
```

### í•µì‹¬ ì•„ì´ë””ì–´
```python
# Flow-based ë°¸ëŸ°ì‹± íŒ¨ëŸ¬ë‹¤ì„
def flow_balancing_paradigm():
    """
    Input: ê²Œì„ ìƒíƒœ ì‹œí€€ìŠ¤ (ì‹œê°„ì— ë”°ë¥¸ ë³€í™”)
    â†“
    Normalizing Flow: ë³µì¡í•œ ê²Œì„ ë¶„í¬ â†’ ë‹¨ìˆœí•œ ê°€ìš°ì‹œì•ˆ ë¶„í¬
    â†“
    Transformer: ì‹œí€€ìŠ¤ ì˜ì¡´ì„± ë° ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜
    â†“
    Inverse Flow: ë‹¨ìˆœ ë¶„í¬ â†’ ìµœì í™”ëœ ê²Œì„ ë¶„í¬
    â†“
    Output: í™•ë¥ ì  ë°¸ëŸ°ì‹± ê²°ê³¼ (ë¶ˆí™•ì‹¤ì„± í¬í•¨)
    """
    pass
```

## ğŸ”„ Normalizing Flow ì•„í‚¤í…ì²˜

### Flow-based ê²Œì„ ìƒíƒœ ë³€í™˜
```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.distributions import Normal
import numpy as np

class CouplingLayer(nn.Module):
    """Coupling Layer for Normalizing Flow"""

    def __init__(self, input_dim: int, hidden_dim: int = 256):
        super().__init__()
        self.input_dim = input_dim
        self.mask = self.create_mask()

        # Scale and Translation networks
        self.scale_net = nn.Sequential(
            nn.Linear(input_dim // 2, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim // 2),
            nn.Tanh()  # Bounded scaling
        )

        self.translate_net = nn.Sequential(
            nn.Linear(input_dim // 2, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim // 2)
        )

    def create_mask(self):
        """Create alternating mask for coupling"""
        mask = torch.zeros(self.input_dim)
        mask[::2] = 1  # Every other dimension
        return mask

    def forward(self, x, reverse=False):
        """Forward/Inverse transformation"""
        mask = self.mask.to(x.device)

        if not reverse:
            # Forward: x -> z
            x_masked = x * mask
            x_unmasked = x * (1 - mask)

            scale = self.scale_net(x_masked)
            translate = self.translate_net(x_masked)

            z_unmasked = x_unmasked * torch.exp(scale) + translate
            z = x_masked + z_unmasked * (1 - mask)

            log_det = scale.sum(dim=-1)
            return z, log_det
        else:
            # Inverse: z -> x
            z_masked = x * mask
            z_unmasked = x * (1 - mask)

            scale = self.scale_net(z_masked)
            translate = self.translate_net(z_masked)

            x_unmasked = (z_unmasked - translate) * torch.exp(-scale)
            x = z_masked + x_unmasked * (1 - mask)

            log_det = -scale.sum(dim=-1)
            return x, log_det

class GameStateFlow(nn.Module):
    """Normalizing Flow for Game State Distribution"""

    def __init__(self, game_state_dim: int = 648, num_layers: int = 8):
        super().__init__()
        self.game_state_dim = game_state_dim
        self.num_layers = num_layers

        # Stack of coupling layers
        self.layers = nn.ModuleList([
            CouplingLayer(game_state_dim) for _ in range(num_layers)
        ])

        # Base distribution (standard Gaussian)
        self.base_dist = Normal(
            torch.zeros(game_state_dim),
            torch.ones(game_state_dim)
        )

    def forward(self, x):
        """Transform game state to base distribution"""
        log_det_total = 0
        z = x

        for layer in self.layers:
            z, log_det = layer(z, reverse=False)
            log_det_total += log_det

        # Calculate log probability
        log_prob_base = self.base_dist.log_prob(z).sum(dim=-1)
        log_prob = log_prob_base + log_det_total

        return z, log_prob

    def inverse(self, z):
        """Transform from base distribution to game state"""
        log_det_total = 0
        x = z

        # Reverse order for inverse
        for layer in reversed(self.layers):
            x, log_det = layer(x, reverse=True)
            log_det_total += log_det

        return x, log_det_total

    def sample(self, num_samples: int, device='cpu'):
        """Sample from learned game state distribution"""
        z = self.base_dist.sample((num_samples,)).to(device)
        x, _ = self.inverse(z)
        return x

class ConditionalGameFlow(nn.Module):
    """Conditional Flow for Context-aware Balancing"""

    def __init__(self, game_state_dim: int = 648, context_dim: int = 64):
        super().__init__()
        self.context_dim = context_dim

        # Context encoder
        self.context_encoder = nn.Sequential(
            nn.Linear(context_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 256),
            nn.ReLU(),
            nn.Linear(256, 128)
        )

        # Conditional coupling layers
        self.layers = nn.ModuleList([
            ConditionalCouplingLayer(game_state_dim, 128)
            for _ in range(8)
        ])

        self.base_dist = Normal(
            torch.zeros(game_state_dim),
            torch.ones(game_state_dim)
        )

    def forward(self, x, context):
        """Conditional transformation"""
        context_encoded = self.context_encoder(context)

        log_det_total = 0
        z = x

        for layer in self.layers:
            z, log_det = layer(z, context_encoded, reverse=False)
            log_det_total += log_det

        log_prob_base = self.base_dist.log_prob(z).sum(dim=-1)
        log_prob = log_prob_base + log_det_total

        return z, log_prob

    def conditional_sample(self, context, num_samples: int = 1):
        """Sample conditioned on context (game situation)"""
        context_encoded = self.context_encoder(context)

        z = self.base_dist.sample((num_samples,)).to(context.device)
        x = z

        for layer in reversed(self.layers):
            x, _ = layer(x, context_encoded, reverse=True)

        return x

class ConditionalCouplingLayer(nn.Module):
    """Context-aware Coupling Layer"""

    def __init__(self, input_dim: int, context_dim: int):
        super().__init__()
        self.input_dim = input_dim
        self.context_dim = context_dim
        self.mask = self.create_mask()

        # Context-conditioned networks
        self.scale_net = nn.Sequential(
            nn.Linear(input_dim // 2 + context_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, input_dim // 2),
            nn.Tanh()
        )

        self.translate_net = nn.Sequential(
            nn.Linear(input_dim // 2 + context_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, input_dim // 2)
        )

    def create_mask(self):
        mask = torch.zeros(self.input_dim)
        mask[::2] = 1
        return mask

    def forward(self, x, context, reverse=False):
        """Context-conditioned transformation"""
        mask = self.mask.to(x.device)

        if not reverse:
            x_masked = x * mask
            x_unmasked = x * (1 - mask)

            # Concatenate with context
            scale_input = torch.cat([x_masked, context], dim=-1)
            translate_input = torch.cat([x_masked, context], dim=-1)

            scale = self.scale_net(scale_input)
            translate = self.translate_net(translate_input)

            z_unmasked = x_unmasked * torch.exp(scale) + translate
            z = x_masked + z_unmasked * (1 - mask)

            log_det = scale.sum(dim=-1)
            return z, log_det
        else:
            z_masked = x * mask
            z_unmasked = x * (1 - mask)

            scale_input = torch.cat([z_masked, context], dim=-1)
            translate_input = torch.cat([z_masked, context], dim=-1)

            scale = self.scale_net(scale_input)
            translate = self.translate_net(translate_input)

            x_unmasked = (z_unmasked - translate) * torch.exp(-scale)
            x = z_masked + x_unmasked * (1 - mask)

            log_det = -scale.sum(dim=-1)
            return x, log_det
```

## ğŸ¤– Transformer ì‹œí€€ìŠ¤ ëª¨ë¸ë§

### ê²Œì„ ìƒíƒœ ì‹œí€€ìŠ¤ Transformer
```python
class GameSequenceTransformer(nn.Module):
    """Transformer for Game State Sequence Modeling"""

    def __init__(self,
                 game_state_dim: int = 648,
                 d_model: int = 512,
                 nhead: int = 8,
                 num_layers: int = 6,
                 max_seq_len: int = 100):
        super().__init__()

        self.d_model = d_model
        self.max_seq_len = max_seq_len

        # Input projection
        self.input_projection = nn.Linear(game_state_dim, d_model)

        # Positional encoding
        self.pos_encoding = PositionalEncoding(d_model, max_seq_len)

        # Transformer encoder
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=2048,
            dropout=0.1,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)

        # Output heads
        self.balance_head = nn.Linear(d_model, 3)  # 3D balance vector
        self.uncertainty_head = nn.Linear(d_model, 3)  # Uncertainty estimation
        self.next_state_head = nn.Linear(d_model, game_state_dim)  # Next state prediction

    def forward(self, game_sequence, mask=None):
        """Process game state sequence"""
        batch_size, seq_len, _ = game_sequence.shape

        # Project to model dimension
        x = self.input_projection(game_sequence)

        # Add positional encoding
        x = self.pos_encoding(x)

        # Transformer encoding
        if mask is not None:
            # Create attention mask
            attn_mask = self.create_attention_mask(mask)
        else:
            attn_mask = None

        encoded = self.transformer(x, src_key_padding_mask=attn_mask)

        # Use last token for predictions
        last_hidden = encoded[:, -1, :]

        # Multiple heads
        balance_vector = self.balance_head(last_hidden)
        uncertainty = torch.exp(self.uncertainty_head(last_hidden))  # Positive uncertainty
        next_state = self.next_state_head(last_hidden)

        return {
            'balance_vector': balance_vector,
            'uncertainty': uncertainty,
            'next_state_prediction': next_state,
            'sequence_encoding': encoded
        }

    def create_attention_mask(self, padding_mask):
        """Create attention mask for variable length sequences"""
        return padding_mask

class PositionalEncoding(nn.Module):
    """Sinusoidal Positional Encoding"""

    def __init__(self, d_model: int, max_len: int = 5000):
        super().__init__()

        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)

        div_term = torch.exp(torch.arange(0, d_model, 2).float() *
                           (-np.log(10000.0) / d_model))

        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)

        self.register_buffer('pe', pe)

    def forward(self, x):
        return x + self.pe[:x.size(1), :].transpose(0, 1)

class MultiHeadAttentionBalancer(nn.Module):
    """Multi-Head Attention for Balance Relationships"""

    def __init__(self, d_model: int = 512, num_heads: int = 8):
        super().__init__()
        self.d_model = d_model
        self.num_heads = num_heads
        self.head_dim = d_model // num_heads

        self.q_linear = nn.Linear(d_model, d_model)
        self.k_linear = nn.Linear(d_model, d_model)
        self.v_linear = nn.Linear(d_model, d_model)
        self.out_linear = nn.Linear(d_model, d_model)

        self.balance_weights = nn.Parameter(torch.randn(num_heads, 1))

    def forward(self, tower_states, race_states, environment_states):
        """Attention between towers, races, and environment"""
        batch_size = tower_states.size(0)

        # Compute Q, K, V
        Q = self.q_linear(tower_states).view(batch_size, -1, self.num_heads, self.head_dim)
        K = self.k_linear(race_states).view(batch_size, -1, self.num_heads, self.head_dim)
        V = self.v_linear(environment_states).view(batch_size, -1, self.num_heads, self.head_dim)

        # Transpose for attention computation
        Q = Q.transpose(1, 2)  # (batch, heads, seq, head_dim)
        K = K.transpose(1, 2)
        V = V.transpose(1, 2)

        # Scaled dot-product attention
        scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.head_dim)
        attention_weights = F.softmax(scores, dim=-1)

        # Apply attention to values
        attended = torch.matmul(attention_weights, V)

        # Concatenate heads
        attended = attended.transpose(1, 2).contiguous().view(
            batch_size, -1, self.d_model
        )

        # Final linear transformation
        output = self.out_linear(attended)

        # Balance-aware weighting
        balance_weighted = output * self.balance_weights.view(1, 1, -1)

        return balance_weighted, attention_weights
```

## ğŸŒŠ í†µí•© Flow-Transformer ì‹œìŠ¤í…œ

### ì™„ì „í•œ ë°¸ëŸ°ì‹± ì•„í‚¤í…ì²˜
```python
class FlowTransformerBalancer(nn.Module):
    """Complete Flow + Transformer Balancing System"""

    def __init__(self,
                 game_state_dim: int = 648,
                 context_dim: int = 64,
                 sequence_length: int = 50):
        super().__init__()

        # Normalizing Flow components
        self.game_flow = ConditionalGameFlow(game_state_dim, context_dim)

        # Transformer components
        self.sequence_transformer = GameSequenceTransformer(
            game_state_dim=game_state_dim,
            max_seq_len=sequence_length
        )

        # Attention-based balancer
        self.attention_balancer = MultiHeadAttentionBalancer()

        # Context encoder for flow conditioning
        self.context_encoder = nn.Sequential(
            nn.Linear(64, 128),  # Environment + player state
            nn.ReLU(),
            nn.Linear(128, context_dim)
        )

        # Uncertainty quantification
        self.uncertainty_estimator = nn.Sequential(
            nn.Linear(game_state_dim + 3, 256),  # State + balance vector
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 1),
            nn.Sigmoid()  # Uncertainty score [0, 1]
        )

    def forward(self, game_sequence, environment_context, player_context):
        """Complete forward pass"""
        batch_size, seq_len, state_dim = game_sequence.shape

        # 1. Encode context
        full_context = torch.cat([environment_context, player_context], dim=-1)
        encoded_context = self.context_encoder(full_context)

        # 2. Transformer sequence processing
        transformer_output = self.sequence_transformer(game_sequence)
        balance_vector = transformer_output['balance_vector']
        sequence_encoding = transformer_output['sequence_encoding']

        # 3. Flow-based distribution modeling
        current_state = game_sequence[:, -1, :]  # Last state in sequence
        z, log_prob = self.game_flow(current_state, encoded_context)

        # 4. Generate balanced state
        balanced_state = self.game_flow.conditional_sample(
            encoded_context, num_samples=1
        ).squeeze(1)

        # 5. Uncertainty estimation
        uncertainty_input = torch.cat([current_state, balance_vector], dim=-1)
        uncertainty_score = self.uncertainty_estimator(uncertainty_input)

        return {
            'balanced_state': balanced_state,
            'balance_vector': balance_vector,
            'uncertainty_score': uncertainty_score,
            'log_probability': log_prob,
            'latent_representation': z,
            'sequence_encoding': sequence_encoding
        }

    def sample_balanced_states(self, context, num_samples: int = 10):
        """Sample multiple balanced states with uncertainty"""
        encoded_context = self.context_encoder(context)

        # Sample from flow
        samples = self.game_flow.conditional_sample(
            encoded_context, num_samples=num_samples
        )

        # Estimate uncertainty for each sample
        uncertainties = []
        for sample in samples:
            # Dummy balance vector for uncertainty estimation
            dummy_balance = torch.zeros(3).to(sample.device)
            uncertainty_input = torch.cat([sample, dummy_balance], dim=-1)
            uncertainty = self.uncertainty_estimator(uncertainty_input.unsqueeze(0))
            uncertainties.append(uncertainty.item())

        return samples, uncertainties

    def get_attention_insights(self, tower_states, race_states, env_states):
        """Get interpretable attention weights"""
        balanced_output, attention_weights = self.attention_balancer(
            tower_states, race_states, env_states
        )

        # Analyze attention patterns
        attention_insights = {
            'tower_race_attention': attention_weights.mean(dim=1),  # Average over heads
            'dominant_relationships': attention_weights.max(dim=-1)[1],
            'attention_entropy': self.calculate_attention_entropy(attention_weights)
        }

        return balanced_output, attention_insights

    def calculate_attention_entropy(self, attention_weights):
        """Calculate entropy of attention distribution"""
        # Avoid log(0) by adding small epsilon
        eps = 1e-8
        log_attention = torch.log(attention_weights + eps)
        entropy = -(attention_weights * log_attention).sum(dim=-1)
        return entropy

# Training and Inference
class FlowTransformerTrainer:
    """Training system for Flow + Transformer"""

    def __init__(self, model: FlowTransformerBalancer):
        self.model = model
        self.optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)

    def train_step(self, batch):
        """Single training step"""
        game_sequences = batch['sequences']
        env_context = batch['environment']
        player_context = batch['players']
        target_balance = batch['target_balance']

        # Forward pass
        output = self.model(game_sequences, env_context, player_context)

        # Multiple loss components
        losses = self.calculate_losses(output, target_balance, game_sequences)
        total_loss = sum(losses.values())

        # Backward pass
        self.optimizer.zero_grad()
        total_loss.backward()
        self.optimizer.step()

        return losses

    def calculate_losses(self, output, target_balance, sequences):
        """Multi-component loss function"""

        # 1. Balance vector loss
        balance_loss = F.mse_loss(output['balance_vector'], target_balance)

        # 2. Flow likelihood loss (maximize probability of good states)
        likelihood_loss = -output['log_probability'].mean()

        # 3. Uncertainty calibration loss
        uncertainty_loss = self.calibration_loss(
            output['uncertainty_score'],
            output['balanced_state'],
            sequences[:, -1, :]  # Current state
        )

        # 4. Sequence consistency loss
        consistency_loss = self.sequence_consistency_loss(
            output['sequence_encoding'],
            sequences
        )

        return {
            'balance_loss': balance_loss * 1.0,
            'likelihood_loss': likelihood_loss * 0.5,
            'uncertainty_loss': uncertainty_loss * 0.3,
            'consistency_loss': consistency_loss * 0.2
        }

    def calibration_loss(self, uncertainty, balanced_state, current_state):
        """Uncertainty calibration loss"""
        state_difference = F.mse_loss(balanced_state, current_state, reduction='none')
        state_difference = state_difference.mean(dim=-1)

        # Uncertainty should correlate with state difference
        target_uncertainty = torch.sigmoid(state_difference)
        return F.mse_loss(uncertainty.squeeze(), target_uncertainty)

    def sequence_consistency_loss(self, encoding, sequences):
        """Sequence consistency loss"""
        # Predict next state from encoding
        predicted_next = self.model.sequence_transformer.next_state_head(
            encoding[:, -1, :]
        )

        # Compare with actual next state (if available)
        if sequences.size(1) > 1:
            actual_current = sequences[:, -1, :]
            return F.mse_loss(predicted_next, actual_current)
        else:
            return torch.tensor(0.0, device=encoding.device)
```

## ğŸš€ ì‹¤ì‹œê°„ ì¶”ë¡  ë° ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”

### ì‹¤ì‹œê°„ ë°¸ëŸ°ì‹± ì—”ì§„
```python
class RealTimeFlowBalancer:
    """ì‹¤ì‹œê°„ Flow + Transformer ë°¸ëŸ°ì‹± ì—”ì§„"""

    def __init__(self, model_path: str):
        self.model = FlowTransformerBalancer()
        self.load_model(model_path)
        self.model.eval()

        # ì‹¤ì‹œê°„ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë²„í¼
        self.sequence_buffer = []
        self.max_sequence_length = 50

        # ë¶ˆí™•ì‹¤ì„± ì„ê³„ê°’
        self.uncertainty_threshold = 0.7
        self.confidence_threshold = 0.8

        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.inference_times = []
        self.uncertainty_history = []

    def real_time_balance(self, current_game_state: Dict) -> Dict:
        """ì‹¤ì‹œê°„ ê²Œì„ ë°¸ëŸ°ì‹±"""
        start_time = time.time()

        # 1. ê²Œì„ ìƒíƒœë¥¼ ì‹œí€€ìŠ¤ ë²„í¼ì— ì¶”ê°€
        self.update_sequence_buffer(current_game_state)

        # 2. ì»¨í…ìŠ¤íŠ¸ ì¸ì½”ë”©
        context = self.encode_game_context(current_game_state)

        # 3. ë‹¤ì¤‘ ìƒ˜í”Œë§ìœ¼ë¡œ ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”
        balanced_samples, uncertainties = self.sample_with_uncertainty(
            context, num_samples=10
        )

        # 4. ìµœì  ìƒ˜í”Œ ì„ íƒ
        best_sample, confidence = self.select_best_sample(
            balanced_samples, uncertainties
        )

        # 5. ì–´í…ì…˜ ë¶„ì„ìœ¼ë¡œ í•´ì„ ê°€ëŠ¥ì„± ì œê³µ
        attention_insights = self.analyze_attention_patterns(
            current_game_state, context
        )

        # 6. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        inference_time = time.time() - start_time
        self.inference_times.append(inference_time)
        self.uncertainty_history.append(1 - confidence)

        return {
            'balanced_state': best_sample,
            'confidence': confidence,
            'uncertainty_score': 1 - confidence,
            'attention_insights': attention_insights,
            'inference_time': inference_time,
            'requires_human_review': confidence < self.confidence_threshold,
            'alternative_samples': balanced_samples[:3]  # Top 3 alternatives
        }

    def sample_with_uncertainty(self, context: torch.Tensor,
                               num_samples: int = 10) -> Tuple[List, List]:
        """ë¶ˆí™•ì‹¤ì„±ì„ ê³ ë ¤í•œ ë‹¤ì¤‘ ìƒ˜í”Œë§"""

        with torch.no_grad():
            # Flowì—ì„œ ë‹¤ì¤‘ ìƒ˜í”Œ ìƒì„±
            samples, sample_uncertainties = self.model.sample_balanced_states(
                context, num_samples=num_samples
            )

            # ê° ìƒ˜í”Œì˜ í’ˆì§ˆ í‰ê°€
            sample_qualities = []
            for sample in samples:
                quality = self.evaluate_sample_quality(sample, context)
                sample_qualities.append(quality)

            # ë¶ˆí™•ì‹¤ì„±ê³¼ í’ˆì§ˆì„ ê²°í•©í•œ ì ìˆ˜
            combined_scores = []
            for quality, uncertainty in zip(sample_qualities, sample_uncertainties):
                # ë†’ì€ í’ˆì§ˆ, ë‚®ì€ ë¶ˆí™•ì‹¤ì„±ì´ ì¢‹ìŒ
                score = quality * (1 - uncertainty)
                combined_scores.append(score)

            # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
            sorted_indices = np.argsort(combined_scores)[::-1]
            sorted_samples = [samples[i] for i in sorted_indices]
            sorted_uncertainties = [sample_uncertainties[i] for i in sorted_indices]

            return sorted_samples, sorted_uncertainties

    def evaluate_sample_quality(self, sample: torch.Tensor,
                               context: torch.Tensor) -> float:
        """ìƒ˜í”Œ í’ˆì§ˆ í‰ê°€"""

        # 1. ë§¤íŠ¸ë¦­ìŠ¤ ì œì•½ ì¡°ê±´ í™•ì¸
        matrices = sample.view(-1, 2, 2)  # Reshape to matrices
        constraint_score = self.check_matrix_constraints(matrices)

        # 2. ì»¨í…ìŠ¤íŠ¸ ì í•©ì„± í™•ì¸
        context_score = self.check_context_fitness(sample, context)

        # 3. ë°¸ëŸ°ìŠ¤ í’ˆì§ˆ í™•ì¸
        balance_score = self.check_balance_quality(matrices)

        # ê°€ì¤‘ í‰ê· 
        quality = (
            constraint_score * 0.4 +
            context_score * 0.3 +
            balance_score * 0.3
        )

        return quality

    def check_matrix_constraints(self, matrices: torch.Tensor) -> float:
        """ë§¤íŠ¸ë¦­ìŠ¤ ì œì•½ ì¡°ê±´ í™•ì¸"""

        scores = []
        for matrix in matrices:
            # í”„ë¡œë² ë‹ˆìš°ìŠ¤ ë…¸ë¦„ ì²´í¬
            norm = torch.norm(matrix, 'fro')
            norm_score = 1.0 if 1.8 <= norm <= 2.2 else 0.5

            # í–‰ë ¬ì‹ ì²´í¬
            det = torch.det(matrix)
            det_score = 1.0 if 0.0 <= det <= 2.0 else 0.5

            # ëŒ€ê°í•© ì²´í¬
            trace = torch.trace(matrix)
            trace_score = 1.0 if 1.5 <= trace <= 2.5 else 0.5

            matrix_score = (norm_score + det_score + trace_score) / 3
            scores.append(matrix_score)

        return np.mean(scores)

    def select_best_sample(self, samples: List, uncertainties: List) -> Tuple[torch.Tensor, float]:
        """ìµœì  ìƒ˜í”Œ ì„ íƒ"""

        # ì´ë¯¸ ì •ë ¬ëœ ìƒíƒœì´ë¯€ë¡œ ì²« ë²ˆì§¸ê°€ ìµœê³ 
        best_sample = samples[0]
        best_uncertainty = uncertainties[0]

        # ì‹ ë¢°ë„ ê³„ì‚° (1 - ë¶ˆí™•ì‹¤ì„±)
        confidence = 1 - best_uncertainty

        # ì¶”ê°€ ê²€ì¦: ë‹¤ë¥¸ ìƒ˜í”Œë“¤ê³¼ì˜ ì¼ê´€ì„± í™•ì¸
        if len(samples) > 1:
            consistency = self.check_sample_consistency(samples[:3])
            confidence *= consistency

        return best_sample, confidence

    def check_sample_consistency(self, top_samples: List) -> float:
        """ìƒìœ„ ìƒ˜í”Œë“¤ ê°„ì˜ ì¼ê´€ì„± í™•ì¸"""

        if len(top_samples) < 2:
            return 1.0

        # ìƒ˜í”Œë“¤ ê°„ì˜ í‰ê·  ê±°ë¦¬ ê³„ì‚°
        distances = []
        for i in range(len(top_samples)):
            for j in range(i + 1, len(top_samples)):
                dist = torch.norm(top_samples[i] - top_samples[j], p=2)
                distances.append(dist.item())

        avg_distance = np.mean(distances)

        # ê±°ë¦¬ê°€ ì‘ì„ìˆ˜ë¡ ì¼ê´€ì„±ì´ ë†’ìŒ
        consistency = 1.0 / (1.0 + avg_distance)

        return consistency

    def analyze_attention_patterns(self, game_state: Dict,
                                 context: torch.Tensor) -> Dict:
        """ì–´í…ì…˜ íŒ¨í„´ ë¶„ì„ìœ¼ë¡œ í•´ì„ ê°€ëŠ¥ì„± ì œê³µ"""

        # ê²Œì„ ìƒíƒœë¥¼ êµ¬ì„± ìš”ì†Œë³„ë¡œ ë¶„ë¦¬
        tower_states = self.extract_tower_states(game_state)
        race_states = self.extract_race_states(game_state)
        env_states = self.extract_environment_states(game_state)

        # ì–´í…ì…˜ ë¶„ì„
        with torch.no_grad():
            balanced_output, attention_insights = self.model.get_attention_insights(
                tower_states, race_states, env_states
            )

        # í•´ì„ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        interpretable_insights = {
            'dominant_tower_race_pairs': self.interpret_attention_weights(
                attention_insights['tower_race_attention']
            ),
            'attention_focus': self.get_attention_focus(
                attention_insights['attention_entropy']
            ),
            'balance_reasoning': self.generate_balance_reasoning(
                attention_insights
            )
        }

        return interpretable_insights

    def interpret_attention_weights(self, attention_weights: torch.Tensor) -> List[Dict]:
        """ì–´í…ì…˜ ê°€ì¤‘ì¹˜ë¥¼ í•´ì„ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜"""

        # ìƒìœ„ 5ê°œ ì–´í…ì…˜ ê´€ê³„ ì¶”ì¶œ
        top_k = 5
        flat_weights = attention_weights.flatten()
        top_indices = torch.topk(flat_weights, top_k).indices

        interpretations = []
        for idx in top_indices:
            # 2D ì¸ë±ìŠ¤ë¡œ ë³€í™˜
            tower_idx = idx // attention_weights.size(1)
            race_idx = idx % attention_weights.size(1)
            weight = flat_weights[idx].item()

            interpretation = {
                'tower_index': tower_idx.item(),
                'race_index': race_idx.item(),
                'attention_weight': weight,
                'relationship_strength': 'strong' if weight > 0.7 else 'moderate' if weight > 0.4 else 'weak'
            }
            interpretations.append(interpretation)

        return interpretations

    def generate_balance_reasoning(self, attention_insights: Dict) -> str:
        """ë°¸ëŸ°ì‹± ì¶”ë¡  ê³¼ì •ì„ ìì—°ì–´ë¡œ ì„¤ëª…"""

        reasoning_parts = []

        # ì–´í…ì…˜ ì—”íŠ¸ë¡œí”¼ ë¶„ì„
        entropy = attention_insights['attention_entropy'].mean().item()
        if entropy > 2.0:
            reasoning_parts.append("ë³µì¡í•œ ë‹¤ì¤‘ ìš”ì†Œ ìƒí˜¸ì‘ìš©ì´ ê°ì§€ë¨")
        elif entropy > 1.0:
            reasoning_parts.append("ì¤‘ê°„ ìˆ˜ì¤€ì˜ ì „ëµì  ë³µì¡ì„±")
        else:
            reasoning_parts.append("ë‹¨ìˆœí•˜ê³  ì§‘ì¤‘ëœ ì „ëµ íŒ¨í„´")

        # ì§€ë°°ì  ê´€ê³„ ë¶„ì„
        dominant_relationships = attention_insights['dominant_relationships']
        unique_relationships = len(torch.unique(dominant_relationships))

        if unique_relationships > 5:
            reasoning_parts.append("ë‹¤ì–‘í•œ ì¢…ì¡±-íƒ€ì›Œ ì¡°í•©ì´ í™œìš©ë¨")
        else:
            reasoning_parts.append("íŠ¹ì • ì¡°í•©ì— ì§‘ì¤‘ëœ ì „ëµ")

        return " | ".join(reasoning_parts)

class UncertaintyQuantifier:
    """ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™” ì „ë¬¸ í´ë˜ìŠ¤"""

    def __init__(self):
        self.calibration_data = []
        self.uncertainty_types = [
            'aleatoric',    # ë°ì´í„° ê³ ìœ  ë¶ˆí™•ì‹¤ì„±
            'epistemic',    # ëª¨ë¸ ì§€ì‹ ë¶ˆí™•ì‹¤ì„±
            'distributional' # ë¶„í¬ ì™¸ ë°ì´í„° ë¶ˆí™•ì‹¤ì„±
        ]

    def quantify_uncertainty(self, model_output: Dict,
                           game_context: Dict) -> Dict[str, float]:
        """ë‹¤ì°¨ì› ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”"""

        # 1. Aleatoric ë¶ˆí™•ì‹¤ì„± (ë°ì´í„° ê³ ìœ )
        aleatoric = self.estimate_aleatoric_uncertainty(
            model_output['balanced_state'],
            game_context
        )

        # 2. Epistemic ë¶ˆí™•ì‹¤ì„± (ëª¨ë¸ ì§€ì‹)
        epistemic = self.estimate_epistemic_uncertainty(
            model_output['sequence_encoding'],
            model_output['latent_representation']
        )

        # 3. Distributional ë¶ˆí™•ì‹¤ì„± (ë¶„í¬ ì™¸)
        distributional = self.estimate_distributional_uncertainty(
            model_output['log_probability']
        )

        # 4. ì¢…í•© ë¶ˆí™•ì‹¤ì„±
        total_uncertainty = self.combine_uncertainties(
            aleatoric, epistemic, distributional
        )

        return {
            'aleatoric_uncertainty': aleatoric,
            'epistemic_uncertainty': epistemic,
            'distributional_uncertainty': distributional,
            'total_uncertainty': total_uncertainty,
            'confidence_interval': self.calculate_confidence_interval(total_uncertainty),
            'reliability_score': 1 - total_uncertainty
        }

    def estimate_aleatoric_uncertainty(self, balanced_state: torch.Tensor,
                                     game_context: Dict) -> float:
        """ë°ì´í„° ê³ ìœ  ë¶ˆí™•ì‹¤ì„± ì¶”ì •"""

        # ê²Œì„ ìƒí™©ì˜ ë³µì¡ì„± ê¸°ë°˜ ë¶ˆí™•ì‹¤ì„±
        complexity_factors = [
            len(game_context.get('active_players', [])),
            len(game_context.get('active_events', [])),
            game_context.get('game_progress', 0.5)
        ]

        complexity_score = np.mean(complexity_factors)

        # ìƒíƒœ ë³€í™”ì˜ í¬ê¸°
        if hasattr(self, 'previous_state'):
            state_change = torch.norm(balanced_state - self.previous_state).item()
            change_uncertainty = min(state_change / 10.0, 1.0)
        else:
            change_uncertainty = 0.5

        self.previous_state = balanced_state.clone()

        aleatoric = (complexity_score + change_uncertainty) / 2
        return min(aleatoric, 1.0)

    def estimate_epistemic_uncertainty(self, sequence_encoding: torch.Tensor,
                                     latent_representation: torch.Tensor) -> float:
        """ëª¨ë¸ ì§€ì‹ ë¶ˆí™•ì‹¤ì„± ì¶”ì •"""

        # ì ì¬ í‘œí˜„ì˜ ë¶„ì‚°
        latent_variance = torch.var(latent_representation).item()

        # ì‹œí€€ìŠ¤ ì¸ì½”ë”©ì˜ ì¼ê´€ì„±
        if sequence_encoding.size(1) > 1:
            encoding_consistency = torch.var(
                sequence_encoding, dim=1
            ).mean().item()
        else:
            encoding_consistency = 0.5

        # ëª¨ë¸ í™œì„±í™”ì˜ ì—”íŠ¸ë¡œí”¼
        activation_entropy = self.calculate_activation_entropy(sequence_encoding)

        epistemic = (latent_variance + encoding_consistency + activation_entropy) / 3
        return min(epistemic, 1.0)

    def estimate_distributional_uncertainty(self, log_probability: torch.Tensor) -> float:
        """ë¶„í¬ ì™¸ ë¶ˆí™•ì‹¤ì„± ì¶”ì •"""

        # ë¡œê·¸ í™•ë¥ ì´ ë‚®ì„ìˆ˜ë¡ ë¶„í¬ ì™¸ ê°€ëŠ¥ì„± ë†’ìŒ
        avg_log_prob = log_probability.mean().item()

        # ì •ê·œí™” (ì¼ë°˜ì ìœ¼ë¡œ -10 ~ 0 ë²”ìœ„)
        normalized_prob = (avg_log_prob + 10) / 10
        distributional = 1 - max(0, min(1, normalized_prob))

        return distributional

    def calculate_activation_entropy(self, activations: torch.Tensor) -> float:
        """í™œì„±í™” ì—”íŠ¸ë¡œí”¼ ê³„ì‚°"""

        # í™œì„±í™”ë¥¼ í™•ë¥  ë¶„í¬ë¡œ ë³€í™˜
        probs = F.softmax(activations.flatten(), dim=0)

        # ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
        log_probs = torch.log(probs + 1e-8)
        entropy = -(probs * log_probs).sum().item()

        # ì •ê·œí™” (ìµœëŒ€ ì—”íŠ¸ë¡œí”¼ë¡œ ë‚˜ëˆ”)
        max_entropy = np.log(len(probs))
        normalized_entropy = entropy / max_entropy

        return normalized_entropy

    def combine_uncertainties(self, aleatoric: float, epistemic: float,
                            distributional: float) -> float:
        """ë¶ˆí™•ì‹¤ì„±ë“¤ì„ ê²°í•©"""

        # ê°€ì¤‘ í‰ê·  (epistemicì´ ê°€ì¥ ì¤‘ìš”)
        weights = [0.3, 0.5, 0.2]  # [aleatoric, epistemic, distributional]
        uncertainties = [aleatoric, epistemic, distributional]

        combined = sum(w * u for w, u in zip(weights, uncertainties))

        return min(combined, 1.0)

    def calculate_confidence_interval(self, uncertainty: float) -> Tuple[float, float]:
        """ì‹ ë¢° êµ¬ê°„ ê³„ì‚°"""

        # ë¶ˆí™•ì‹¤ì„±ì„ ì‹ ë¢° êµ¬ê°„ í­ìœ¼ë¡œ ë³€í™˜
        interval_width = uncertainty * 2.0  # Â±uncertainty

        center = 0.5  # ì¤‘ì‹¬ê°’ (ì •ê·œí™”ëœ ê³µê°„ì—ì„œ)
        lower = max(0.0, center - interval_width / 2)
        upper = min(1.0, center + interval_width / 2)

        return (lower, upper)

class PerformanceMonitor:
    """ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""

    def __init__(self):
        self.metrics_history = {
            'inference_time': [],
            'uncertainty_score': [],
            'confidence_score': [],
            'sample_quality': [],
            'attention_entropy': []
        }

        self.alert_thresholds = {
            'max_inference_time': 0.1,  # 100ms
            'min_confidence': 0.7,
            'max_uncertainty': 0.5
        }

    def update_metrics(self, inference_result: Dict):
        """ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""

        self.metrics_history['inference_time'].append(
            inference_result['inference_time']
        )
        self.metrics_history['uncertainty_score'].append(
            inference_result['uncertainty_score']
        )
        self.metrics_history['confidence_score'].append(
            inference_result['confidence']
        )

        # ìµœê·¼ 100ê°œ ê¸°ë¡ë§Œ ìœ ì§€
        for key in self.metrics_history:
            if len(self.metrics_history[key]) > 100:
                self.metrics_history[key] = self.metrics_history[key][-100:]

    def check_alerts(self) -> List[str]:
        """ì„±ëŠ¥ ì•Œë¦¼ í™•ì¸"""

        alerts = []

        # ìµœê·¼ ì¶”ë¡  ì‹œê°„ í™•ì¸
        if self.metrics_history['inference_time']:
            recent_time = self.metrics_history['inference_time'][-1]
            if recent_time > self.alert_thresholds['max_inference_time']:
                alerts.append(f"ì¶”ë¡  ì‹œê°„ ì´ˆê³¼: {recent_time:.3f}s")

        # ìµœê·¼ ì‹ ë¢°ë„ í™•ì¸
        if self.metrics_history['confidence_score']:
            recent_confidence = self.metrics_history['confidence_score'][-1]
            if recent_confidence < self.alert_thresholds['min_confidence']:
                alerts.append(f"ì‹ ë¢°ë„ ë¶€ì¡±: {recent_confidence:.3f}")

        # í‰ê·  ë¶ˆí™•ì‹¤ì„± í™•ì¸
        if len(self.metrics_history['uncertainty_score']) >= 10:
            avg_uncertainty = np.mean(self.metrics_history['uncertainty_score'][-10:])
            if avg_uncertainty > self.alert_thresholds['max_uncertainty']:
                alerts.append(f"ë¶ˆí™•ì‹¤ì„± ì¦ê°€: {avg_uncertainty:.3f}")

        return alerts

    def generate_performance_report(self) -> Dict:
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""

        report = {}

        for metric_name, values in self.metrics_history.items():
            if values:
                report[metric_name] = {
                    'mean': np.mean(values),
                    'std': np.std(values),
                    'min': np.min(values),
                    'max': np.max(values),
                    'recent_trend': self.calculate_trend(values[-20:]) if len(values) >= 20 else 'insufficient_data'
                }

        return report

    def calculate_trend(self, values: List[float]) -> str:
        """íŠ¸ë Œë“œ ê³„ì‚°"""

        if len(values) < 2:
            return 'insufficient_data'

        # ì„ í˜• íšŒê·€ë¡œ íŠ¸ë Œë“œ ê³„ì‚°
        x = np.arange(len(values))
        slope = np.polyfit(x, values, 1)[0]

        if slope > 0.01:
            return 'increasing'
        elif slope < -0.01:
            return 'decreasing'
        else:
            return 'stable'

# ì‚¬ìš© ì˜ˆì‹œ
def main_flow_transformer_system():
    """Flow + Transformer ì‹œìŠ¤í…œ ë©”ì¸ ì‹¤í–‰"""

    print("ğŸŒŠ Defense Allies Flow + Transformer ë°¸ëŸ°ì‹± ì‹œìŠ¤í…œ")
    print("=" * 60)

    # 1. ì‹¤ì‹œê°„ ë°¸ëŸ°ì„œ ì´ˆê¸°í™”
    balancer = RealTimeFlowBalancer('flow_transformer_model.pth')
    uncertainty_quantifier = UncertaintyQuantifier()
    performance_monitor = PerformanceMonitor()

    # 2. ì‹œë®¬ë ˆì´ì…˜ ê²Œì„ ìƒíƒœ
    game_state = {
        'tower_matrices': np.random.rand(20, 2, 2),
        'active_players': ['player1', 'player2', 'player3'],
        'game_progress': 0.6,
        'environment': {'time': 'day', 'weather': 'clear', 'terrain': 'forest'},
        'active_events': ['meteor_shower']
    }

    # 3. ì‹¤ì‹œê°„ ë°¸ëŸ°ì‹± ì‹¤í–‰
    result = balancer.real_time_balance(game_state)

    # 4. ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”
    uncertainty_analysis = uncertainty_quantifier.quantify_uncertainty(
        result, game_state
    )

    # 5. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    performance_monitor.update_metrics(result)
    alerts = performance_monitor.check_alerts()

    # 6. ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ¯ ë°¸ëŸ°ì‹± ê²°ê³¼:")
    print(f"ì‹ ë¢°ë„: {result['confidence']:.3f}")
    print(f"ë¶ˆí™•ì‹¤ì„±: {result['uncertainty_score']:.3f}")
    print(f"ì¶”ë¡  ì‹œê°„: {result['inference_time']:.3f}ì´ˆ")
    print(f"ì¸ê°„ ê²€í†  í•„ìš”: {'ì˜ˆ' if result['requires_human_review'] else 'ì•„ë‹ˆì˜¤'}")

    print(f"\nğŸ“Š ë¶ˆí™•ì‹¤ì„± ë¶„ì„:")
    for key, value in uncertainty_analysis.items():
        if isinstance(value, (int, float)):
            print(f"{key}: {value:.3f}")

    print(f"\nğŸ” ì–´í…ì…˜ ì¸ì‚¬ì´íŠ¸:")
    print(f"ë°¸ëŸ°ì‹± ì¶”ë¡ : {result['attention_insights']['balance_reasoning']}")

    if alerts:
        print(f"\nâš ï¸ ì„±ëŠ¥ ì•Œë¦¼:")
        for alert in alerts:
            print(f"  - {alert}")

    print(f"\nâœ… Flow + Transformer ë°¸ëŸ°ì‹± ì™„ë£Œ!")

if __name__ == "__main__":
    main_flow_transformer_system()
```

## ğŸ† Flow + Transformer vs ì˜¤í† ì¸ì½”ë” ë¹„êµ

### ê¸°ìˆ ì  ìš°ìˆ˜ì„±
```yaml
ì •ë³´ ë³´ì¡´:
  ì˜¤í† ì¸ì½”ë”: ì •ë³´ ì†ì‹¤ ë¶ˆê°€í”¼ (ì••ì¶• ê³¼ì •ì—ì„œ)
  Flow + Transformer: ì™„ì „ ê°€ì—­ ë³€í™˜ (ì •ë³´ ì†ì‹¤ ì—†ìŒ)

í™•ë¥  ëª¨ë¸ë§:
  ì˜¤í† ì¸ì½”ë”: ì  ì¶”ì • (ë‹¨ì¼ ê²°ê³¼)
  Flow + Transformer: í™•ë¥  ë¶„í¬ ëª¨ë¸ë§ (ë‹¤ì¤‘ ê²°ê³¼ + ë¶ˆí™•ì‹¤ì„±)

ì‹œí€€ìŠ¤ ì²˜ë¦¬:
  ì˜¤í† ì¸ì½”ë”: ë‹¨ì¼ ì‹œì  ì²˜ë¦¬
  Flow + Transformer: ì‹œê°„ì  ì˜ì¡´ì„± ëª¨ë¸ë§

í•´ì„ ê°€ëŠ¥ì„±:
  ì˜¤í† ì¸ì½”ë”: ë¸”ë™ë°•ìŠ¤
  Flow + Transformer: ì–´í…ì…˜ ê¸°ë°˜ í•´ì„ ê°€ëŠ¥ì„±
```

### ì‹¤ìš©ì  ì¥ì 
```yaml
ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”:
  - Aleatoric (ë°ì´í„° ê³ ìœ )
  - Epistemic (ëª¨ë¸ ì§€ì‹)
  - Distributional (ë¶„í¬ ì™¸)
  - ì‹ ë¢° êµ¬ê°„ ì œê³µ

ë‹¤ì¤‘ ìƒ˜í”Œë§:
  - 10ê°œ í›„ë³´ ì¤‘ ìµœì  ì„ íƒ
  - ëŒ€ì•ˆ ì†”ë£¨ì…˜ ì œê³µ
  - ì¼ê´€ì„± ê²€ì¦

ì‹¤ì‹œê°„ ì„±ëŠ¥:
  - 100ms ì´í•˜ ì¶”ë¡  ì‹œê°„
  - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼
  - ìë™ í’ˆì§ˆ ê´€ë¦¬
```

### ê²Œì„ ì‚°ì—… í˜ì‹ 
```yaml
ì„¸ê³„ ìµœì´ˆ:
  - Flow-based ê²Œì„ ë°¸ëŸ°ì‹±
  - í™•ë¥ ì  ë°¸ëŸ°ìŠ¤ ì¡°ì •
  - ë¶ˆí™•ì‹¤ì„± ê¸°ë°˜ ì˜ì‚¬ê²°ì •

ì‹¤ìš©ì  ê°€ì¹˜:
  - ì¸ê°„ ê²€í†  í•„ìš”ì„± ìë™ íŒë‹¨
  - ë‹¤ì¤‘ ëŒ€ì•ˆ ì œì‹œ
  - ì‹¤ì‹œê°„ ì„±ëŠ¥ ë³´ì¥
```

**Defense AlliesëŠ” ì´ì œ ì°¨ì„¸ëŒ€ AI ê¸°ìˆ ë¡œ ë¬´ì¥í•œ ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ì˜ ë°¸ëŸ°ì‹± ì‹œìŠ¤í…œì„ ë³´ìœ í–ˆìŠµë‹ˆë‹¤!** ğŸŒŠğŸ¤–

---

**ë‹¤ìŒ ë‹¨ê³„**: Diffusion ëª¨ë¸ ê¸°ë°˜ ë°¸ëŸ°ì‹± ì‹œìŠ¤í…œ ì„¤ê³„ ë° 3ì„¸ëŒ€ AI í†µí•©
